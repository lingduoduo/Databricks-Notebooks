{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc94837a-86f2-4ff8-b1bf-c40fbcbcd8a7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-adk in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d9280ef4-342c-4594-95af-be4fb68de2dd/lib/python3.11/site-packages (1.22.1)\nRequirement already satisfied: litellm in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d9280ef4-342c-4594-95af-be4fb68de2dd/lib/python3.11/site-packages (1.80.15)\nRequirement already satisfied: databricks-sdk in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d9280ef4-342c-4594-95af-be4fb68de2dd/lib/python3.11/site-packages (0.77.0)\nCollecting langchain\n  Downloading langchain-1.2.3-py3-none-any.whl.metadata (4.9 kB)\nCollecting databricks-langchain\n  Downloading databricks_langchain-0.12.1-py3-none-any.whl.metadata (3.0 kB)\nCollecting langchain\n  Downloading langchain-0.3.7-py3-none-any.whl.metadata (7.1 kB)\nCollecting faiss-cpu\n  Downloading faiss_cpu-1.13.2-cp310-abi3-manylinux_2_27_aarch64.manylinux_2_28_aarch64.whl.metadata (7.6 kB)\nCollecting wikipedia\n  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n  Preparing metadata (setup.py): started\n  Preparing metadata (setup.py): finished with status 'done'\nCollecting langgraph==0.5.3\n  Downloading langgraph-0.5.3-py3-none-any.whl.metadata (6.9 kB)\nRequirement already satisfied: PyYAML>=5.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d9280ef4-342c-4594-95af-be4fb68de2dd/lib/python3.11/site-packages (from langchain) (6.0.3)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d9280ef4-342c-4594-95af-be4fb68de2dd/lib/python3.11/site-packages (from langchain) (2.0.45)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d9280ef4-342c-4594-95af-be4fb68de2dd/lib/python3.11/site-packages (from langchain) (3.13.3)\nCollecting langchain-core<0.4.0,>=0.3.15 (from langchain)\n  Downloading langchain_core-0.3.83-py3-none-any.whl.metadata (3.2 kB)\nCollecting langchain-text-splitters<0.4.0,>=0.3.0 (from langchain)\n  Downloading langchain_text_splitters-0.3.11-py3-none-any.whl.metadata (1.8 kB)\nCollecting langsmith<0.2.0,>=0.1.17 (from langchain)\n  Downloading langsmith-0.1.147-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: numpy<2,>=1 in /databricks/python3/lib/python3.11/site-packages (from langchain) (1.23.5)\nRequirement already satisfied: pydantic<3.0.0,>=2.7.4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d9280ef4-342c-4594-95af-be4fb68de2dd/lib/python3.11/site-packages (from langchain) (2.12.5)\nRequirement already satisfied: requests<3,>=2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d9280ef4-342c-4594-95af-be4fb68de2dd/lib/python3.11/site-packages (from langchain) (2.32.5)\nRequirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d9280ef4-342c-4594-95af-be4fb68de2dd/lib/python3.11/site-packages (from langchain) (9.1.2)\nCollecting langgraph-checkpoint<3.0.0,>=2.1.0 (from langgraph==0.5.3)\n  Downloading langgraph_checkpoint-2.1.2-py3-none-any.whl.metadata (4.2 kB)\nCollecting langgraph-prebuilt<0.6.0,>=0.5.0 (from langgraph==0.5.3)\n  Downloading langgraph_prebuilt-0.5.2-py3-none-any.whl.metadata (4.5 kB)\nCollecting langgraph-sdk<0.2.0,>=0.1.42 (from langgraph==0.5.3)\n  Downloading langgraph_sdk-0.1.74-py3-none-any.whl.metadata (1.5 kB)\nCollecting xxhash>=3.5.0 (from langgraph==0.5.3)\n  Downloading xxhash-3.6.0-cp311-cp311-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl.metadata (13 kB)\nRequirement already satisfied: aiosqlite>=0.21.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d9280ef4-342c-4594-95af-be4fb68de2dd/lib/python3.11/site-packages (from google-adk) (0.22.1)\nRequirement already satisfied: anyio<5.0.0,>=4.9.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d9280ef4-342c-4594-95af-be4fb68de2dd/lib/python3.11/site-packages (from google-adk) (4.12.1)\nRequirement already satisfied: authlib<2.0.0,>=1.5.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d9280ef4-342c-4594-95af-be4fb68de2dd/lib/python3.11/site-packages (from google-adk) (1.6.6)\nRequirement already satisfied: click<9.0.0,>=8.1.8 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d9280ef4-342c-4594-95af-be4fb68de2dd/lib/python3.11/site-packages (from google-adk) (8.3.1)\nRequirement already satisfied: fastapi<0.124.0,>=0.115.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d9280ef4-342c-4594-95af-be4fb68de2dd/lib/python3.11/site-packages (from google-adk) (0.123.10)\nRequirement already satisfied: google-api-python-client<3.0.0,>=2.157.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d9280ef4-342c-4594-95af-be4fb68de2dd/lib/python3.11/site-packages (from google-adk) (2.187.0)\nRequirement already satisfied: google-auth>=2.47.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d9280ef4-342c-4594-95af-be4fb68de2dd/lib/python3.11/site-packages (from google-adk) (2.47.0)\nRequirement already satisfied: google-cloud-aiplatform<2.0.0,>=1.132.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d9280ef4-342c-4594-95af-be4fb68de2dd/lib/python3.11/site-packages (from google-cloud-aiplatform[agent-engines]<2.0.0,>=1.132.0->google-adk) (1.133.0)\nRequirement already satisfied: google-cloud-bigquery-storage>=2.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d9280ef4-342c-4594-95af-be4fb68de2dd/lib/python3.11/site-packages (from google-adk) (2.36.0)\nRequirement already satisfied: google-cloud-bigquery>=2.2.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d9280ef4-342c-4594-95af-be4fb68de2dd/lib/python3.11/site-packages (from google-adk) (3.40.0)\nRequirement already satisfied: google-cloud-bigtable>=2.32.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d9280ef4-342c-4594-95af-be4fb68de2dd/lib/python3.11/site-packages (from google-adk) (2.35.0)\nRequirement already satisfied: google-cloud-discoveryengine<0.14.0,>=0.13.12 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d9280ef4-342c-4594-95af-be4fb68de2dd/lib/python3.11/site-packages (from google-adk) (0.13.12)\nRequirement already satisfied: google-cloud-pubsub<3.0.0,>=2.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d9280ef4-342c-4594-95af-be4fb68de2dd/lib/python3.11/site-packages (from google-adk) (2.34.0)\nRequirement already satisfied: google-cloud-secret-manager<3.0.0,>=2.22.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d9280ef4-342c-4594-95af-be4fb68de2dd/lib/python3.11/site-packages (from google-adk) (2.26.0)\nRequirement already satisfied: google-cloud-spanner<4.0.0,>=3.56.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d9280ef4-342c-4594-95af-be4fb68de2dd/lib/python3.11/site-packages (from google-adk) (3.61.0)\nRequirement already satisfied: google-cloud-speech<3.0.0,>=2.30.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d9280ef4-342c-4594-95af-be4fb68de2dd/lib/python3.11/site-packages (from google-adk) (2.35.0)\nRequirement already satisfied: google-cloud-storage<4.0.0,>=2.18.0 in /databricks/python3/lib/python3.11/site-packages (from google-adk) (2.18.2)\nRequirement already satisfied: google-genai<2.0.0,>=1.56.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d9280ef4-342c-4594-95af-be4fb68de2dd/lib/python3.11/site-packages (from google-adk) (1.57.0)\nRequirement already satisfied: graphviz<1.0.0,>=0.20.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d9280ef4-342c-4594-95af-be4fb68de2dd/lib/python3.11/site-packages (from google-adk) (0.21)\nRequirement already satisfied: jsonschema<5.0.0,>=4.23.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d9280ef4-342c-4594-95af-be4fb68de2dd/lib/python3.11/site-packages (from google-adk) (4.26.0)\nRequirement already satisfied: mcp<2.0.0,>=1.10.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d9280ef4-342c-4594-95af-be4fb68de2dd/lib/python3.11/site-packages (from google-adk) (1.25.0)\nRequirement already satisfied: opentelemetry-api<=1.37.0,>=1.37.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d9280ef4-342c-4594-95af-be4fb68de2dd/lib/python3.11/site-packages (from google-adk) (1.37.0)\nRequirement already satisfied: opentelemetry-exporter-gcp-logging<2.0.0,>=1.9.0a0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d9280ef4-342c-4594-95af-be4fb68de2dd/lib/python3.11/site-packages (from google-adk) (1.11.0a0)\nRequirement already satisfied: opentelemetry-exporter-gcp-monitoring<2.0.0,>=1.9.0a0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d9280ef4-342c-4594-95af-be4fb68de2dd/lib/python3.11/site-packages (from google-adk) (1.11.0a0)\nRequirement already satisfied: opentelemetry-exporter-gcp-trace<2.0.0,>=1.9.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d9280ef4-342c-4594-95af-be4fb68de2dd/lib/python3.11/site-packages (from google-adk) (1.11.0)\nRequirement already satisfied: opentelemetry-exporter-otlp-proto-http>=1.36.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d9280ef4-342c-4594-95af-be4fb68de2dd/lib/python3.11/site-packages (from google-adk) (1.37.0)\nRequirement already satisfied: opentelemetry-resourcedetector-gcp<2.0.0,>=1.9.0a0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d9280ef4-342c-4594-95af-be4fb68de2dd/lib/python3.11/site-packages (from google-adk) (1.11.0a0)\nRequirement already satisfied: opentelemetry-sdk<=1.37.0,>=1.37.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d9280ef4-342c-4594-95af-be4fb68de2dd/lib/python3.11/site-packages (from google-adk) (1.37.0)\nRequirement already satisfied: pyarrow>=14.0.0 in /databricks/python3/lib/python3.11/site-packages (from google-adk) (14.0.1)\nRequirement already satisfied: python-dateutil<3.0.0,>=2.9.0.post0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d9280ef4-342c-4594-95af-be4fb68de2dd/lib/python3.11/site-packages (from google-adk) (2.9.0.post0)\nRequirement already satisfied: python-dotenv<2.0.0,>=1.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d9280ef4-342c-4594-95af-be4fb68de2dd/lib/python3.11/site-packages (from google-adk) (1.2.1)\nRequirement already satisfied: sqlalchemy-spanner>=1.14.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d9280ef4-342c-4594-95af-be4fb68de2dd/lib/python3.11/site-packages (from google-adk) (1.17.2)\nRequirement already satisfied: starlette<1.0.0,>=0.49.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d9280ef4-342c-4594-95af-be4fb68de2dd/lib/python3.11/site-packages (from google-adk) (0.50.0)\nRequirement already satisfied: typing-extensions<5,>=4.5 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d9280ef4-342c-4594-95af-be4fb68de2dd/lib/python3.11/site-packages (from google-adk) (4.15.0)\nRequirement already satisfied: tzlocal<6.0,>=5.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d9280ef4-342c-4594-95af-be4fb68de2dd/lib/python3.11/site-packages (from google-adk) (5.3.1)\nRequirement already satisfied: uvicorn<1.0.0,>=0.34.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d9280ef4-342c-4594-95af-be4fb68de2dd/lib/python3.11/site-packages (from google-adk) (0.40.0)\nRequirement already satisfied: watchdog<7.0.0,>=6.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d9280ef4-342c-4594-95af-be4fb68de2dd/lib/python3.11/site-packages (from google-adk) (6.0.0)\nRequirement already satisfied: websockets<16.0.0,>=15.0.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d9280ef4-342c-4594-95af-be4fb68de2dd/lib/python3.11/site-packages (from google-adk) (15.0.1)\nRequirement already satisfied: fastuuid>=0.13.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d9280ef4-342c-4594-95af-be4fb68de2dd/lib/python3.11/site-packages (from litellm) (0.14.0)\nRequirement already satisfied: grpcio!=1.68.*,!=1.69.*,!=1.70.*,!=1.71.0,!=1.71.1,!=1.72.0,!=1.72.1,!=1.73.0,>=1.62.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d9280ef4-342c-4594-95af-be4fb68de2dd/lib/python3.11/site-packages (from litellm) (1.76.0)\nRequirement already satisfied: httpx>=0.23.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d9280ef4-342c-4594-95af-be4fb68de2dd/lib/python3.11/site-packages (from litellm) (0.28.1)\nRequirement already satisfied: importlib-metadata>=6.8.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d9280ef4-342c-4594-95af-be4fb68de2dd/lib/python3.11/site-packages (from litellm) (8.7.1)\nRequirement already satisfied: jinja2<4.0.0,>=3.1.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d9280ef4-342c-4594-95af-be4fb68de2dd/lib/python3.11/site-packages (from litellm) (3.1.6)\nRequirement already satisfied: openai>=2.8.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d9280ef4-342c-4594-95af-be4fb68de2dd/lib/python3.11/site-packages (from litellm) (2.15.0)\nRequirement already satisfied: tiktoken>=0.7.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d9280ef4-342c-4594-95af-be4fb68de2dd/lib/python3.11/site-packages (from litellm) (0.12.0)\nRequirement already satisfied: tokenizers in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d9280ef4-342c-4594-95af-be4fb68de2dd/lib/python3.11/site-packages (from litellm) (0.22.2)\nRequirement already satisfied: protobuf!=5.26.*,!=5.27.*,!=5.28.*,!=5.29.0,!=5.29.1,!=5.29.2,!=5.29.3,!=5.29.4,!=6.30.0,!=6.30.1,!=6.31.0,<7.0,>=4.25.8 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d9280ef4-342c-4594-95af-be4fb68de2dd/lib/python3.11/site-packages (from databricks-sdk) (5.29.5)\nCollecting databricks-ai-bridge>=0.4.2 (from databricks-langchain)\n  Downloading databricks_ai_bridge-0.11.0-py3-none-any.whl.metadata (6.9 kB)\nCollecting databricks-mcp>=0.5.1 (from databricks-langchain)\n  Downloading databricks_mcp-0.5.1-py3-none-any.whl.metadata (1.5 kB)\nCollecting databricks-vectorsearch>=0.50 (from databricks-langchain)\n  Downloading databricks_vectorsearch-0.63-py3-none-any.whl.metadata (2.8 kB)\nCollecting langchain-mcp-adapters>=0.1.13 (from databricks-langchain)\n  Downloading langchain_mcp_adapters-0.2.1-py3-none-any.whl.metadata (10 kB)\nINFO: pip is looking at multiple versions of databricks-langchain to determine which version is compatible with other requirements. This could take a while.\nCollecting databricks-langchain\n  Downloading databricks_langchain-0.12.0-py3-none-any.whl.metadata (3.0 kB)\n  Downloading databricks_langchain-0.11.0-py3-none-any.whl.metadata (2.9 kB)\n  Downloading databricks_langchain-0.9.0-py3-none-any.whl.metadata (2.7 kB)\n  Downloading databricks_langchain-0.8.2-py3-none-any.whl.metadata (2.7 kB)\nCollecting mlflow>=2.20.1 (from databricks-langchain)\n  Downloading mlflow-3.8.1-py3-none-any.whl.metadata (31 kB)\nCollecting unitycatalog-langchain>=0.2.0 (from unitycatalog-langchain[databricks]>=0.2.0->databricks-langchain)\n  Downloading unitycatalog_langchain-0.3.0-py3-none-any.whl.metadata (6.6 kB)\nCollecting numpy<2,>=1 (from langchain)\n  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (62 kB)\nRequirement already satisfied: packaging in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d9280ef4-342c-4594-95af-be4fb68de2dd/lib/python3.11/site-packages (from faiss-cpu) (25.0)\nCollecting beautifulsoup4 (from wikipedia)\n  Downloading beautifulsoup4-4.14.3-py3-none-any.whl.metadata (3.8 kB)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d9280ef4-342c-4594-95af-be4fb68de2dd/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.6.1)\nRequirement already satisfied: aiosignal>=1.4.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d9280ef4-342c-4594-95af-be4fb68de2dd/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\nRequirement already satisfied: attrs>=17.3.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d9280ef4-342c-4594-95af-be4fb68de2dd/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (25.4.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d9280ef4-342c-4594-95af-be4fb68de2dd/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.8.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d9280ef4-342c-4594-95af-be4fb68de2dd/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.7.0)\nRequirement already satisfied: propcache>=0.2.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d9280ef4-342c-4594-95af-be4fb68de2dd/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.4.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d9280ef4-342c-4594-95af-be4fb68de2dd/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.22.0)\nRequirement already satisfied: idna>=2.8 in /databricks/python3/lib/python3.11/site-packages (from anyio<5.0.0,>=4.9.0->google-adk) (3.4)\nRequirement already satisfied: cryptography in /databricks/python3/lib/python3.11/site-packages (from authlib<2.0.0,>=1.5.1->google-adk) (41.0.3)\nCollecting mlflow-skinny>=2.19.0 (from databricks-ai-bridge>=0.4.2->databricks-langchain)\n  Downloading mlflow_skinny-3.8.1-py3-none-any.whl.metadata (31 kB)\nRequirement already satisfied: pandas in /databricks/python3/lib/python3.11/site-packages (from databricks-ai-bridge>=0.4.2->databricks-langchain) (1.5.3)\nCollecting tabulate>=0.9.0 (from databricks-ai-bridge>=0.4.2->databricks-langchain)\n  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\nCollecting deprecation>=2 (from databricks-vectorsearch>=0.50->databricks-langchain)\n  Downloading deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)\nRequirement already satisfied: annotated-doc>=0.0.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d9280ef4-342c-4594-95af-be4fb68de2dd/lib/python3.11/site-packages (from fastapi<0.124.0,>=0.115.0->google-adk) (0.0.4)\nRequirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/lib/python3/dist-packages (from google-api-python-client<3.0.0,>=2.157.0->google-adk) (0.20.2)\nRequirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d9280ef4-342c-4594-95af-be4fb68de2dd/lib/python3.11/site-packages (from google-api-python-client<3.0.0,>=2.157.0->google-adk) (0.3.0)\nRequirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d9280ef4-342c-4594-95af-be4fb68de2dd/lib/python3.11/site-packages (from google-api-python-client<3.0.0,>=2.157.0->google-adk) (2.29.0)\nRequirement already satisfied: uritemplate<5,>=3.0.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d9280ef4-342c-4594-95af-be4fb68de2dd/lib/python3.11/site-packages (from google-api-python-client<3.0.0,>=2.157.0->google-adk) (4.2.0)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /databricks/python3/lib/python3.11/site-packages (from google-auth>=2.47.0->google-adk) (0.2.8)\nRequirement already satisfied: rsa<5,>=3.1.4 in /databricks/python3/lib/python3.11/site-packages (from google-auth>=2.47.0->google-adk) (4.9)\nRequirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /databricks/python3/lib/python3.11/site-packages (from google-cloud-aiplatform<2.0.0,>=1.132.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.132.0->google-adk) (1.25.0)\nRequirement already satisfied: google-cloud-resource-manager<3.0.0,>=1.3.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d9280ef4-342c-4594-95af-be4fb68de2dd/lib/python3.11/site-packages (from google-cloud-aiplatform<2.0.0,>=1.132.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.132.0->google-adk) (1.15.0)\nRequirement already satisfied: docstring_parser<1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d9280ef4-342c-4594-95af-be4fb68de2dd/lib/python3.11/site-packages (from google-cloud-aiplatform<2.0.0,>=1.132.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.132.0->google-adk) (0.17.0)\nRequirement already satisfied: cloudpickle<4.0,>=3.0 in /databricks/python3/lib/python3.11/site-packages (from google-cloud-aiplatform[agent-engines]<2.0.0,>=1.132.0->google-adk) (3.0.0)\nRequirement already satisfied: google-cloud-trace<2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d9280ef4-342c-4594-95af-be4fb68de2dd/lib/python3.11/site-packages (from google-cloud-aiplatform[agent-engines]<2.0.0,>=1.132.0->google-adk) (1.17.0)\nRequirement already satisfied: google-cloud-logging<4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d9280ef4-342c-4594-95af-be4fb68de2dd/lib/python3.11/site-packages (from google-cloud-aiplatform[agent-engines]<2.0.0,>=1.132.0->google-adk) (3.13.0)\nRequirement already satisfied: google-cloud-core<3.0.0,>=2.4.1 in /databricks/python3/lib/python3.11/site-packages (from google-cloud-bigquery>=2.2.0->google-adk) (2.4.1)\nRequirement already satisfied: google-resumable-media<3.0.0,>=2.0.0 in /databricks/python3/lib/python3.11/site-packages (from google-cloud-bigquery>=2.2.0->google-adk) (2.7.2)\nRequirement already satisfied: grpc-google-iam-v1<1.0.0,>=0.12.4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d9280ef4-342c-4594-95af-be4fb68de2dd/lib/python3.11/site-packages (from google-cloud-bigtable>=2.32.0->google-adk) (0.14.3)\nRequirement already satisfied: google-crc32c<2.0.0dev,>=1.5.0 in /databricks/python3/lib/python3.11/site-packages (from google-cloud-bigtable>=2.32.0->google-adk) (1.6.0)\nRequirement already satisfied: grpcio-status>=1.33.2 in /databricks/python3/lib/python3.11/site-packages (from google-cloud-pubsub<3.0.0,>=2.0.0->google-adk) (1.69.0)\nRequirement already satisfied: sqlparse>=0.4.4 in /databricks/python3/lib/python3.11/site-packages (from google-cloud-spanner<4.0.0,>=3.56.0->google-adk) (0.5.1)\nRequirement already satisfied: grpc-interceptor>=0.15.4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d9280ef4-342c-4594-95af-be4fb68de2dd/lib/python3.11/site-packages (from google-cloud-spanner<4.0.0,>=3.56.0->google-adk) (0.15.4)\nRequirement already satisfied: opentelemetry-semantic-conventions>=0.43b0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d9280ef4-342c-4594-95af-be4fb68de2dd/lib/python3.11/site-packages (from google-cloud-spanner<4.0.0,>=3.56.0->google-adk) (0.58b0)\nRequirement already satisfied: google-cloud-monitoring>=2.16.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d9280ef4-342c-4594-95af-be4fb68de2dd/lib/python3.11/site-packages (from google-cloud-spanner<4.0.0,>=3.56.0->google-adk) (2.28.0)\nRequirement already satisfied: mmh3>=4.1.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d9280ef4-342c-4594-95af-be4fb68de2dd/lib/python3.11/site-packages (from google-cloud-spanner<4.0.0,>=3.56.0->google-adk) (5.2.0)\nRequirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from google-genai<2.0.0,>=1.56.0->google-adk) (1.7.0)\nRequirement already satisfied: sniffio in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d9280ef4-342c-4594-95af-be4fb68de2dd/lib/python3.11/site-packages (from google-genai<2.0.0,>=1.56.0->google-adk) (1.3.1)\nRequirement already satisfied: certifi in /databricks/python3/lib/python3.11/site-packages (from httpx>=0.23.0->litellm) (2023.7.22)\nRequirement already satisfied: httpcore==1.* in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d9280ef4-342c-4594-95af-be4fb68de2dd/lib/python3.11/site-packages (from httpx>=0.23.0->litellm) (1.0.9)\nRequirement already satisfied: h11>=0.16 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d9280ef4-342c-4594-95af-be4fb68de2dd/lib/python3.11/site-packages (from httpcore==1.*->httpx>=0.23.0->litellm) (0.16.0)\nRequirement already satisfied: zipp>=3.20 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d9280ef4-342c-4594-95af-be4fb68de2dd/lib/python3.11/site-packages (from importlib-metadata>=6.8.0->litellm) (3.23.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d9280ef4-342c-4594-95af-be4fb68de2dd/lib/python3.11/site-packages (from jinja2<4.0.0,>=3.1.2->litellm) (3.0.3)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d9280ef4-342c-4594-95af-be4fb68de2dd/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.23.0->google-adk) (2025.9.1)\nRequirement already satisfied: referencing>=0.28.4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d9280ef4-342c-4594-95af-be4fb68de2dd/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.23.0->google-adk) (0.37.0)\nRequirement already satisfied: rpds-py>=0.25.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d9280ef4-342c-4594-95af-be4fb68de2dd/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.23.0->google-adk) (0.30.0)\nINFO: pip is looking at multiple versions of langchain-core to determine which version is compatible with other requirements. This could take a while.\nCollecting langchain-core<0.4.0,>=0.3.15 (from langchain)\n  Downloading langchain_core-0.3.82-py3-none-any.whl.metadata (3.2 kB)\n  Downloading langchain_core-0.3.81-py3-none-any.whl.metadata (3.2 kB)\n  Downloading langchain_core-0.3.80-py3-none-any.whl.metadata (3.2 kB)\n  Downloading langchain_core-0.3.79-py3-none-any.whl.metadata (3.2 kB)\n  Downloading langchain_core-0.3.78-py3-none-any.whl.metadata (3.2 kB)\n  Downloading langchain_core-0.3.77-py3-none-any.whl.metadata (3.2 kB)\n  Downloading langchain_core-0.3.76-py3-none-any.whl.metadata (3.7 kB)\nINFO: pip is still looking at multiple versions of langchain-core to determine which version is compatible with other requirements. This could take a while.\n  Downloading langchain_core-0.3.75-py3-none-any.whl.metadata (5.7 kB)\n  Downloading langchain_core-0.3.74-py3-none-any.whl.metadata (5.8 kB)\n  Downloading langchain_core-0.3.73-py3-none-any.whl.metadata (\n\n*** WARNING: max output size exceeded, skipping output. ***\n\nadata (4.3 kB)\nRequirement already satisfied: matplotlib<4 in /databricks/python3/lib/python3.11/site-packages (from mlflow>=2.20.1->databricks-langchain) (3.7.2)\nRequirement already satisfied: scikit-learn<2 in /databricks/python3/lib/python3.11/site-packages (from mlflow>=2.20.1->databricks-langchain) (1.3.0)\nRequirement already satisfied: scipy<2 in /databricks/python3/lib/python3.11/site-packages (from mlflow>=2.20.1->databricks-langchain) (1.11.1)\nRequirement already satisfied: cachetools<7,>=5.0.0 in /databricks/python3/lib/python3.11/site-packages (from mlflow-skinny>=2.19.0->databricks-ai-bridge>=0.4.2->databricks-langchain) (5.5.0)\nRequirement already satisfied: gitpython<4,>=3.1.9 in /databricks/python3/lib/python3.11/site-packages (from mlflow-skinny>=2.19.0->databricks-ai-bridge>=0.4.2->databricks-langchain) (3.1.43)\nRequirement already satisfied: opentelemetry-proto<3,>=1.9.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d9280ef4-342c-4594-95af-be4fb68de2dd/lib/python3.11/site-packages (from mlflow-skinny>=2.19.0->databricks-ai-bridge>=0.4.2->databricks-langchain) (1.37.0)\nRequirement already satisfied: jiter<1,>=0.10.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d9280ef4-342c-4594-95af-be4fb68de2dd/lib/python3.11/site-packages (from openai>=2.8.0->litellm) (0.12.0)\nRequirement already satisfied: tqdm>4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d9280ef4-342c-4594-95af-be4fb68de2dd/lib/python3.11/site-packages (from openai>=2.8.0->litellm) (4.67.1)\nRequirement already satisfied: googleapis-common-protos~=1.52 in /databricks/python3/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-http>=1.36.0->google-adk) (1.65.0)\nRequirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.37.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d9280ef4-342c-4594-95af-be4fb68de2dd/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-http>=1.36.0->google-adk) (1.37.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d9280ef4-342c-4594-95af-be4fb68de2dd/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\nRequirement already satisfied: pydantic-core==2.41.5 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d9280ef4-342c-4594-95af-be4fb68de2dd/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.5)\nRequirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil<3.0.0,>=2.9.0.post0->google-adk) (1.16.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /databricks/python3/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2.0.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /databricks/python3/lib/python3.11/site-packages (from requests<3,>=2->langchain) (1.26.16)\nRequirement already satisfied: greenlet>=1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d9280ef4-342c-4594-95af-be4fb68de2dd/lib/python3.11/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.3.0)\nRequirement already satisfied: regex>=2022.1.18 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d9280ef4-342c-4594-95af-be4fb68de2dd/lib/python3.11/site-packages (from tiktoken>=0.7.0->litellm) (2025.11.3)\nCollecting langchain-community>=0.4.0 (from unitycatalog-langchain>=0.2.0->unitycatalog-langchain[databricks]>=0.2.0->databricks-langchain)\n  Downloading langchain_community-0.4.1-py3-none-any.whl.metadata (3.0 kB)\nINFO: pip is looking at multiple versions of unitycatalog-langchain to determine which version is compatible with other requirements. This could take a while.\nCollecting unitycatalog-langchain>=0.2.0 (from unitycatalog-langchain[databricks]>=0.2.0->databricks-langchain)\n  Downloading unitycatalog_langchain-0.2.0-py3-none-any.whl.metadata (6.5 kB)\nCollecting unitycatalog-ai (from unitycatalog-langchain>=0.2.0->unitycatalog-langchain[databricks]>=0.2.0->databricks-langchain)\n  Downloading unitycatalog_ai-0.3.2-py3-none-any.whl.metadata (31 kB)\nINFO: pip is looking at multiple versions of unitycatalog-langchain[databricks] to determine which version is compatible with other requirements. This could take a while.\nCollecting soupsieve>=1.6.1 (from beautifulsoup4->wikipedia)\n  Downloading soupsieve-2.8.1-py3-none-any.whl.metadata (4.6 kB)\nRequirement already satisfied: huggingface-hub<2.0,>=0.16.4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d9280ef4-342c-4594-95af-be4fb68de2dd/lib/python3.11/site-packages (from tokenizers->litellm) (1.3.1)\nRequirement already satisfied: Mako in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d9280ef4-342c-4594-95af-be4fb68de2dd/lib/python3.11/site-packages (from alembic!=1.10.0,<2->mlflow>=2.20.1->databricks-langchain) (1.3.10)\nCollecting cffi>=2.0.0 (from cryptography->authlib<2.0.0,>=1.5.1->google-adk)\n  Downloading cffi-2.0.0-cp311-cp311-manylinux2014_aarch64.manylinux_2_17_aarch64.whl.metadata (2.6 kB)\nCollecting blinker>=1.9.0 (from Flask<4->mlflow>=2.20.1->databricks-langchain)\n  Downloading blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\nCollecting itsdangerous>=2.2.0 (from Flask<4->mlflow>=2.20.1->databricks-langchain)\n  Downloading itsdangerous-2.2.0-py3-none-any.whl.metadata (1.9 kB)\nCollecting werkzeug>=3.1.0 (from Flask<4->mlflow>=2.20.1->databricks-langchain)\n  Downloading werkzeug-3.1.5-py3-none-any.whl.metadata (4.0 kB)\nRequirement already satisfied: google-cloud-appengine-logging<2.0.0,>=0.1.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d9280ef4-342c-4594-95af-be4fb68de2dd/lib/python3.11/site-packages (from google-cloud-logging<4->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.132.0->google-adk) (1.8.0)\nRequirement already satisfied: google-cloud-audit-log<1.0.0,>=0.3.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d9280ef4-342c-4594-95af-be4fb68de2dd/lib/python3.11/site-packages (from google-cloud-logging<4->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.132.0->google-adk) (0.4.0)\nCollecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow>=2.20.1->databricks-langchain)\n  Downloading graphql_core-3.2.7-py3-none-any.whl.metadata (11 kB)\nCollecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow>=2.20.1->databricks-langchain)\n  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /databricks/python3/lib/python3.11/site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client<3.0.0,>=2.157.0->google-adk) (3.0.9)\nRequirement already satisfied: filelock in /databricks/python3/lib/python3.11/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm) (3.13.4)\nRequirement already satisfied: fsspec>=2023.5.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d9280ef4-342c-4594-95af-be4fb68de2dd/lib/python3.11/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm) (2026.1.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d9280ef4-342c-4594-95af-be4fb68de2dd/lib/python3.11/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm) (1.2.0)\nRequirement already satisfied: shellingham in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d9280ef4-342c-4594-95af-be4fb68de2dd/lib/python3.11/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm) (1.5.4)\nRequirement already satisfied: typer-slim in /local_disk0/.ephemeral_nfs/envs/pythonEnv-d9280ef4-342c-4594-95af-be4fb68de2dd/lib/python3.11/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm) (0.21.1)\nCollecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain)\n  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\nINFO: pip is looking at multiple versions of langchain-community to determine which version is compatible with other requirements. This could take a while.\nCollecting langchain-community>=0.2.0 (from unitycatalog-langchain>=0.2.0->unitycatalog-langchain[databricks]>=0.2.0->databricks-langchain)\n  Downloading langchain_community-0.4-py3-none-any.whl.metadata (3.0 kB)\n  Downloading langchain_community-0.3.31-py3-none-any.whl.metadata (3.0 kB)\n  Downloading langchain_community-0.3.30-py3-none-any.whl.metadata (3.0 kB)\n  Downloading langchain_community-0.3.29-py3-none-any.whl.metadata (2.9 kB)\n  Downloading langchain_community-0.3.28-py3-none-any.whl.metadata (2.9 kB)\n  Downloading langchain_community-0.3.27-py3-none-any.whl.metadata (2.9 kB)\n  Downloading langchain_community-0.3.26-py3-none-any.whl.metadata (2.9 kB)\nINFO: pip is still looking at multiple versions of langchain-community to determine which version is compatible with other requirements. This could take a while.\n  Downloading langchain_community-0.3.25-py3-none-any.whl.metadata (2.9 kB)\n  Downloading langchain_community-0.3.24-py3-none-any.whl.metadata (2.5 kB)\n  Downloading langchain_community-0.3.23-py3-none-any.whl.metadata (2.5 kB)\n  Downloading langchain_community-0.3.22-py3-none-any.whl.metadata (2.4 kB)\n  Downloading langchain_community-0.3.21-py3-none-any.whl.metadata (2.4 kB)\nINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n  Downloading langchain_community-0.3.20-py3-none-any.whl.metadata (2.4 kB)\n  Downloading langchain_community-0.3.19-py3-none-any.whl.metadata (2.4 kB)\n  Downloading langchain_community-0.3.18-py3-none-any.whl.metadata (2.4 kB)\n  Downloading langchain_community-0.3.17-py3-none-any.whl.metadata (2.4 kB)\n  Downloading langchain_community-0.3.16-py3-none-any.whl.metadata (2.9 kB)\nCollecting dataclasses-json<0.7,>=0.5.7 (from langchain-community>=0.2.0->unitycatalog-langchain>=0.2.0->unitycatalog-langchain[databricks]>=0.2.0->databricks-langchain)\n  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\nCollecting langchain-community>=0.2.0 (from unitycatalog-langchain>=0.2.0->unitycatalog-langchain[databricks]>=0.2.0->databricks-langchain)\n  Downloading langchain_community-0.3.15-py3-none-any.whl.metadata (2.9 kB)\n  Downloading langchain_community-0.3.14-py3-none-any.whl.metadata (2.9 kB)\n  Downloading langchain_community-0.3.13-py3-none-any.whl.metadata (2.9 kB)\n  Downloading langchain_community-0.3.12-py3-none-any.whl.metadata (2.9 kB)\n  Downloading langchain_community-0.3.11-py3-none-any.whl.metadata (2.9 kB)\n  Downloading langchain_community-0.3.10-py3-none-any.whl.metadata (2.9 kB)\n  Downloading langchain_community-0.3.9-py3-none-any.whl.metadata (2.9 kB)\n  Downloading langchain_community-0.3.8-py3-none-any.whl.metadata (2.9 kB)\nCollecting SQLAlchemy<3,>=1.4 (from langchain)\n  Downloading SQLAlchemy-2.0.35-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (9.6 kB)\nCollecting langchain-community>=0.2.0 (from unitycatalog-langchain>=0.2.0->unitycatalog-langchain[databricks]>=0.2.0->databricks-langchain)\n  Downloading langchain_community-0.3.7-py3-none-any.whl.metadata (2.9 kB)\nRequirement already satisfied: contourpy>=1.0.1 in /databricks/python3/lib/python3.11/site-packages (from matplotlib<4->mlflow>=2.20.1->databricks-langchain) (1.0.5)\nRequirement already satisfied: cycler>=0.10 in /databricks/python3/lib/python3.11/site-packages (from matplotlib<4->mlflow>=2.20.1->databricks-langchain) (0.11.0)\nRequirement already satisfied: fonttools>=4.22.0 in /databricks/python3/lib/python3.11/site-packages (from matplotlib<4->mlflow>=2.20.1->databricks-langchain) (4.25.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /databricks/python3/lib/python3.11/site-packages (from matplotlib<4->mlflow>=2.20.1->databricks-langchain) (1.4.4)\nRequirement already satisfied: pillow>=6.2.0 in /databricks/python3/lib/python3.11/site-packages (from matplotlib<4->mlflow>=2.20.1->databricks-langchain) (10.3.0)\nRequirement already satisfied: pytz>=2020.1 in /databricks/python3/lib/python3.11/site-packages (from pandas->databricks-ai-bridge>=0.4.2->databricks-langchain) (2022.7)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /databricks/python3/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.47.0->google-adk) (0.4.8)\nRequirement already satisfied: joblib>=1.1.1 in /databricks/python3/lib/python3.11/site-packages (from scikit-learn<2->mlflow>=2.20.1->databricks-langchain) (1.2.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /databricks/python3/lib/python3.11/site-packages (from scikit-learn<2->mlflow>=2.20.1->databricks-langchain) (2.2.0)\nRequirement already satisfied: nest-asyncio in /databricks/python3/lib/python3.11/site-packages (from unitycatalog-ai->unitycatalog-langchain>=0.2.0->unitycatalog-langchain[databricks]>=0.2.0->databricks-langchain) (1.5.6)\nCollecting unitycatalog-client (from unitycatalog-ai->unitycatalog-langchain>=0.2.0->unitycatalog-langchain[databricks]>=0.2.0->databricks-langchain)\n  Downloading unitycatalog_client-0.3.1-py3-none-any.whl.metadata (7.8 kB)\nRequirement already satisfied: databricks-connect<17.1,>=15.1.0 in /databricks/python3/lib/python3.11/site-packages (from unitycatalog-ai[databricks]; extra == \"databricks\"->unitycatalog-langchain[databricks]>=0.2.0->databricks-langchain) (15.4.15)\nRequirement already satisfied: pycparser in /databricks/python3/lib/python3.11/site-packages (from cffi>=2.0.0->cryptography->authlib<2.0.0,>=1.5.1->google-adk) (2.21)\nRequirement already satisfied: py4j==0.10.9.7 in /databricks/python3/lib/python3.11/site-packages (from databricks-connect<17.1,>=15.1.0->unitycatalog-ai[databricks]; extra == \"databricks\"->unitycatalog-langchain[databricks]>=0.2.0->databricks-langchain) (0.10.9.7)\nRequirement already satisfied: setuptools>=68.0.0 in /databricks/python3/lib/python3.11/site-packages (from databricks-connect<17.1,>=15.1.0->unitycatalog-ai[databricks]; extra == \"databricks\"->unitycatalog-langchain[databricks]>=0.2.0->databricks-langchain) (75.1.0)\nCollecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community>=0.2.0->unitycatalog-langchain>=0.2.0->unitycatalog-langchain[databricks]>=0.2.0->databricks-langchain)\n  Downloading marshmallow-3.26.2-py3-none-any.whl.metadata (7.3 kB)\nCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community>=0.2.0->unitycatalog-langchain>=0.2.0->unitycatalog-langchain[databricks]>=0.2.0->databricks-langchain)\n  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /databricks/python3/lib/python3.11/site-packages (from gitpython<4,>=3.1.9->mlflow-skinny>=2.19.0->databricks-ai-bridge>=0.4.2->databricks-langchain) (4.0.11)\nCollecting aiohttp-retry>=2.8.3 (from unitycatalog-client->unitycatalog-ai->unitycatalog-langchain>=0.2.0->unitycatalog-langchain[databricks]>=0.2.0->databricks-langchain)\n  Downloading aiohttp_retry-2.9.1-py3-none-any.whl.metadata (8.8 kB)\nRequirement already satisfied: smmap<6,>=3.0.1 in /databricks/python3/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny>=2.19.0->databricks-ai-bridge>=0.4.2->databricks-langchain) (5.0.1)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /databricks/python3/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community>=0.2.0->unitycatalog-langchain>=0.2.0->unitycatalog-langchain[databricks]>=0.2.0->databricks-langchain) (0.4.3)\nDownloading langchain-0.3.7-py3-none-any.whl (1.0 MB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/1.0 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.0/1.0 MB\u001B[0m \u001B[31m27.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading langgraph-0.5.3-py3-none-any.whl (143 kB)\nDownloading databricks_langchain-0.8.2-py3-none-any.whl (27 kB)\nDownloading faiss_cpu-1.13.2-cp310-abi3-manylinux_2_27_aarch64.manylinux_2_28_aarch64.whl (11.5 MB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/11.5 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m11.5/11.5 MB\u001B[0m \u001B[31m129.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading databricks_ai_bridge-0.11.0-py3-none-any.whl (23 kB)\nDownloading databricks_vectorsearch-0.63-py3-none-any.whl (19 kB)\nDownloading langchain_core-0.3.63-py3-none-any.whl (438 kB)\nDownloading langsmith-0.1.147-py3-none-any.whl (311 kB)\nDownloading langchain_text_splitters-0.3.8-py3-none-any.whl (32 kB)\nDownloading langgraph_checkpoint-2.1.2-py3-none-any.whl (45 kB)\nDownloading langgraph_prebuilt-0.5.1-py3-none-any.whl (23 kB)\nDownloading langgraph_sdk-0.1.74-py3-none-any.whl (50 kB)\nDownloading mlflow-3.8.1-py3-none-any.whl (9.1 MB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/9.1 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m9.1/9.1 MB\u001B[0m \u001B[31m144.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading mlflow_skinny-3.8.1-py3-none-any.whl (2.5 MB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/2.5 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.5/2.5 MB\u001B[0m \u001B[31m102.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading mlflow_tracing-3.8.1-py3-none-any.whl (1.4 MB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/1.4 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.4/1.4 MB\u001B[0m \u001B[31m57.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (14.2 MB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/14.2 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m14.2/14.2 MB\u001B[0m \u001B[31m111.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading packaging-24.2-py3-none-any.whl (65 kB)\nDownloading unitycatalog_langchain-0.2.0-py3-none-any.whl (5.4 kB)\nDownloading xxhash-3.6.0-cp311-cp311-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl (213 kB)\nDownloading beautifulsoup4-4.14.3-py3-none-any.whl (107 kB)\nDownloading cryptography-46.0.3-cp311-abi3-manylinux_2_34_aarch64.whl (4.3 MB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/4.3 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m4.3/4.3 MB\u001B[0m \u001B[31m127.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\nDownloading docker-7.1.0-py3-none-any.whl (147 kB)\nDownloading flask-3.1.2-py3-none-any.whl (103 kB)\nDownloading flask_cors-6.0.2-py3-none-any.whl (13 kB)\nDownloading graphene-3.4.3-py2.py3-none-any.whl (114 kB)\nDownloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\nDownloading huey-2.6.0-py3-none-any.whl (76 kB)\nDownloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\nDownloading langchain_community-0.3.7-py3-none-any.whl (2.4 MB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/2.4 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.4/2.4 MB\u001B[0m \u001B[31m45.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading SQLAlchemy-2.0.35-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (3.2 MB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/3.2 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m3.2/3.2 MB\u001B[0m \u001B[31m89.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading orjson-3.11.5-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (132 kB)\nDownloading ormsgpack-1.12.1-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (202 kB)\nDownloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\nDownloading soupsieve-2.8.1-py3-none-any.whl (36 kB)\nDownloading tabulate-0.9.0-py3-none-any.whl (35 kB)\nDownloading unitycatalog_ai-0.3.2-py3-none-any.whl (66 kB)\nDownloading blinker-1.9.0-py3-none-any.whl (8.5 kB)\nDownloading cffi-2.0.0-cp311-cp311-manylinux2014_aarch64.manylinux_2_17_aarch64.whl (216 kB)\nDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\nDownloading graphql_core-3.2.7-py3-none-any.whl (207 kB)\nDownloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\nDownloading itsdangerous-2.2.0-py3-none-any.whl (16 kB)\nDownloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\nDownloading werkzeug-3.1.5-py3-none-any.whl (225 kB)\nDownloading unitycatalog_client-0.3.1-py3-none-any.whl (176 kB)\nDownloading aiohttp_retry-2.9.1-py3-none-any.whl (10.0 kB)\nDownloading marshmallow-3.26.2-py3-none-any.whl (50 kB)\nDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\nBuilding wheels for collected packages: wikipedia\n  Building wheel for wikipedia (setup.py): started\n  Building wheel for wikipedia (setup.py): finished with status 'done'\n  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11680 sha256=c8e1ce929d51deee9d23b8967b3732751028c4f8ee241b16b9c3f2f3b3f87ebb\n  Stored in directory: /home/spark-d9280ef4-342c-4594-95af-be/.cache/pip/wheels/8f/ab/cb/45ccc40522d3a1c41e1d2ad53b8f33a62f394011ec38cd71c6\nSuccessfully built wikipedia\nInstalling collected packages: huey, xxhash, werkzeug, typing-inspect, tabulate, SQLAlchemy, soupsieve, packaging, ormsgpack, orjson, numpy, jsonpointer, itsdangerous, graphql-core, cffi, blinker, requests-toolbelt, marshmallow, jsonpatch, gunicorn, graphql-relay, Flask, faiss-cpu, docker, deprecation, cryptography, beautifulsoup4, wikipedia, langsmith, langgraph-sdk, graphene, Flask-CORS, dataclasses-json, aiohttp-retry, unitycatalog-client, langchain-core, unitycatalog-ai, mlflow-tracing, mlflow-skinny, langgraph-checkpoint, langchain-text-splitters, mlflow, langgraph-prebuilt, langchain, databricks-vectorsearch, langgraph, langchain-community, databricks-ai-bridge, unitycatalog-langchain, databricks-langchain\n  Attempting uninstall: SQLAlchemy\n    Found existing installation: SQLAlchemy 2.0.45\n    Uninstalling SQLAlchemy-2.0.45:\n      Successfully uninstalled SQLAlchemy-2.0.45\n  Attempting uninstall: packaging\n    Found existing installation: packaging 25.0\n    Uninstalling packaging-25.0:\n      Successfully uninstalled packaging-25.0\n  Attempting uninstall: numpy\n    Found existing installation: numpy 1.23.5\n    Not uninstalling numpy at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-d9280ef4-342c-4594-95af-be4fb68de2dd\n    Can't uninstall 'numpy'. No files were found to uninstall.\n  Attempting uninstall: cffi\n    Found existing installation: cffi 1.15.1\n    Not uninstalling cffi at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-d9280ef4-342c-4594-95af-be4fb68de2dd\n    Can't uninstall 'cffi'. No files were found to uninstall.\n  Attempting uninstall: blinker\n    Found existing installation: blinker 1.4\n    Not uninstalling blinker at /usr/lib/python3/dist-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-d9280ef4-342c-4594-95af-be4fb68de2dd\n    Can't uninstall 'blinker'. No files were found to uninstall.\n  Attempting uninstall: cryptography\n    Found existing installation: cryptography 41.0.3\n    Not uninstalling cryptography at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-d9280ef4-342c-4594-95af-be4fb68de2dd\n    Can't uninstall 'cryptography'. No files were found to uninstall.\n  Attempting uninstall: mlflow-skinny\n    Found existing installation: mlflow-skinny 2.11.4\n    Not uninstalling mlflow-skinny at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-d9280ef4-342c-4594-95af-be4fb68de2dd\n    Can't uninstall 'mlflow-skinny'. No files were found to uninstall.\nSuccessfully installed Flask-3.1.2 Flask-CORS-6.0.2 SQLAlchemy-2.0.35 aiohttp-retry-2.9.1 beautifulsoup4-4.14.3 blinker-1.9.0 cffi-2.0.0 cryptography-46.0.3 databricks-ai-bridge-0.11.0 databricks-langchain-0.8.2 databricks-vectorsearch-0.63 dataclasses-json-0.6.7 deprecation-2.1.0 docker-7.1.0 faiss-cpu-1.13.2 graphene-3.4.3 graphql-core-3.2.7 graphql-relay-3.2.0 gunicorn-23.0.0 huey-2.6.0 itsdangerous-2.2.0 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.3.7 langchain-community-0.3.7 langchain-core-0.3.63 langchain-text-splitters-0.3.8 langgraph-0.5.3 langgraph-checkpoint-2.1.2 langgraph-prebuilt-0.5.1 langgraph-sdk-0.1.74 langsmith-0.1.147 marshmallow-3.26.2 mlflow-3.8.1 mlflow-skinny-3.8.1 mlflow-tracing-3.8.1 numpy-1.26.4 orjson-3.11.5 ormsgpack-1.12.1 packaging-24.2 requests-toolbelt-1.0.0 soupsieve-2.8.1 tabulate-0.9.0 typing-inspect-0.9.0 unitycatalog-ai-0.3.2 unitycatalog-client-0.3.1 unitycatalog-langchain-0.2.0 werkzeug-3.1.5 wikipedia-1.4.0 xxhash-3.6.0\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install -U google-adk litellm databricks-sdk langchain databricks-langchain langchain==0.3.7 faiss-cpu wikipedia langgraph==0.5.3  databricks_langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c5c4878a-34a0-466d-8a77-34d802a685b2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "76216f23-819f-492c-806f-405888b6d542",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "94c57fc7-083e-4750-87ef-2391de68d4bd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from databricks_langchain import ChatDatabricks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8f6e5561-875a-488f-a0de-08bb989e6823",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "LLM_ENDPOINT_NAME = \"databricks-meta-llama-3-1-8b-instruct\" # Model Serving endpoint name; other option see \"Serving\" under AI/ML tab (e.g. databricks-gpt-oss-20b)\n",
    "\n",
    "llm = ChatDatabricks(endpoint=LLM_ENDPOINT_NAME, temperature=0.2)\n",
    "\n",
    "GOOGLE_API_KEY=\"AI**\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "31eda9d9-0e39-4488-b153-320a55e66025",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM roles initialized: classifier, simple, reasoning, search\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------------------------\n",
    "# LLM Instances by Role (Enterprise Pattern)\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "# Deterministic classifier\n",
    "classifier_llm = ChatDatabricks(\n",
    "    endpoint=LLM_ENDPOINT_NAME,\n",
    "    temperature=0.0,   # STRICT determinism\n",
    ")\n",
    "\n",
    "# Simple direct answers\n",
    "simple_llm = ChatDatabricks(\n",
    "    endpoint=LLM_ENDPOINT_NAME,\n",
    "    temperature=0.2,\n",
    ")\n",
    "\n",
    "# Multi-step reasoning\n",
    "reasoning_llm = ChatDatabricks(\n",
    "    endpoint=LLM_ENDPOINT_NAME,\n",
    "    temperature=0.2,\n",
    ")\n",
    "\n",
    "# Internet-search-style synthesis (prompt-based)\n",
    "search_llm = ChatDatabricks(\n",
    "    endpoint=LLM_ENDPOINT_NAME,\n",
    "    temperature=0.2,\n",
    ")\n",
    "\n",
    "print(\"LLM roles initialized: classifier, simple, reasoning, search\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f6025d65-04c0-4e42-80ed-997d12a29bd3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification chain initialized (JSON-only).\n"
     ]
    }
   ],
   "source": [
    "classification_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "You are an enterprise routing controller.\n",
    "\n",
    "Classify the user prompt into EXACTLY ONE category:\n",
    "- simple\n",
    "- reasoning\n",
    "- internet_search\n",
    "\n",
    "Definitions:\n",
    "- simple: directly answerable; no multi-step reasoning; no fresh data needed\n",
    "- reasoning: requires multi-step logic, comparison, synthesis, or structured thought\n",
    "- internet_search: requires up-to-date or externally verifiable information\n",
    "\n",
    "Hard rules:\n",
    "- Return STRICT JSON only (no markdown, no extra text)\n",
    "- Use ONLY the two keys: classification, reasoning\n",
    "- classification must be exactly one of: \"simple\", \"reasoning\", \"internet_search\"\n",
    "- reasoning must be a short sentence\n",
    "\n",
    "User prompt:\n",
    "{user_prompt}\n",
    "\n",
    "Return JSON (exact keys only):\n",
    "{{\n",
    "  \"classification\": \"simple | reasoning | internet_search\",\n",
    "  \"reasoning\": \"...\"\n",
    "}}\n",
    "\"\"\")\n",
    "\n",
    "classification_chain = classification_prompt | classifier_llm\n",
    "print(\"Classification chain initialized (JSON-only).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d4562b62-3cda-4909-9da2-5052d8d84967",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search (evidence generation) chain initialized.\n"
     ]
    }
   ],
   "source": [
    "search_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "You are a research assistant operating WITHOUT web access.\n",
    "\n",
    "The question requires up-to-date or externally verifiable information.\n",
    "Generate a structured evidence pack to help answer it.\n",
    "\n",
    "Rules:\n",
    "- Do NOT claim real-time access\n",
    "- Clearly mark uncertainty\n",
    "- Be concise and factual\n",
    "- Return STRICT JSON only\n",
    "- Do NOT include markdown or extra text\n",
    "\n",
    "User question:\n",
    "{user_prompt}\n",
    "\n",
    "Return JSON in this exact format:\n",
    "{{\n",
    "  \"key_facts\": [\n",
    "    \"Important factual points relevant to the question\"\n",
    "  ],\n",
    "  \"likely_current_answer\": \"Best estimate based on general knowledge (may be outdated)\",\n",
    "  \"what_to_verify\": [\n",
    "    \"What a human should verify using an authoritative source\"\n",
    "  ],\n",
    "  \"confidence_level\": \"low | medium | high\"\n",
    "}}\n",
    "\"\"\")\n",
    "\n",
    "search_chain = search_prompt | search_llm\n",
    "print(\"Search (evidence generation) chain initialized.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c24944e1-4e3b-452c-bcb2-87016d36f382",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------\n",
    "# Answer generation prompts\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "simple_answer_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "Answer the question directly and concisely.\n",
    "\n",
    "Question:\n",
    "{user_prompt}\n",
    "\"\"\")\n",
    "\n",
    "reasoning_answer_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "Answer the question using clear, step-by-step reasoning.\n",
    "Keep it structured and avoid unnecessary verbosity.\n",
    "\n",
    "Question:\n",
    "{user_prompt}\n",
    "\"\"\")\n",
    "\n",
    "search_answer_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "You do NOT have web access. Use the evidence pack below to answer.\n",
    "Be explicit about uncertainty and what should be verified.\n",
    "\n",
    "Evidence pack (JSON):\n",
    "{evidence_pack}\n",
    "\n",
    "Question:\n",
    "{user_prompt}\n",
    "\n",
    "Answer:\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Generate response based on routing classification\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "def generate_response(user_prompt: str, classification: str, evidence_pack: dict | None = None) -> str:\n",
    "    classification = classification.strip().lower()\n",
    "\n",
    "    if classification == \"simple\":\n",
    "        chain = simple_answer_prompt | simple_llm\n",
    "        msg = chain.invoke({\"user_prompt\": user_prompt})\n",
    "        return msg.content\n",
    "\n",
    "    if classification == \"reasoning\":\n",
    "        chain = reasoning_answer_prompt | reasoning_llm\n",
    "        msg = chain.invoke({\"user_prompt\": user_prompt})\n",
    "        return msg.content\n",
    "\n",
    "    if classification == \"internet_search\":\n",
    "        if evidence_pack is None:\n",
    "            raise ValueError(\"internet_search requires an evidence_pack, but none was provided.\")\n",
    "        chain = search_answer_prompt | search_llm\n",
    "        msg = chain.invoke({\n",
    "            \"user_prompt\": user_prompt,\n",
    "            \"evidence_pack\": json.dumps(evidence_pack, ensure_ascii=False, indent=2),\n",
    "        })\n",
    "        return msg.content\n",
    "\n",
    "    raise ValueError(f\"Unknown classification: {classification}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "36471b4c-67a0-4291-955f-31a98e4e2a6b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Router initialized: run_prompt(user_prompt)\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------------------------\n",
    "# JSON parsing helper (robust to occasional extra text)\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "def parse_json_message(msg) -> dict:\n",
    "    \"\"\"\n",
    "    Extract JSON object from an LLM message safely.\n",
    "    Fails fast if no valid JSON object is found.\n",
    "    \"\"\"\n",
    "    text = msg.content if hasattr(msg, \"content\") else str(msg)\n",
    "    text = text.strip()\n",
    "\n",
    "    # remove accidental code fences\n",
    "    if text.startswith(\"```\"):\n",
    "        text = text.strip(\"`\").strip()\n",
    "\n",
    "    start = text.find(\"{\")\n",
    "    end = text.rfind(\"}\") + 1\n",
    "    if start == -1 or end <= start:\n",
    "        raise ValueError(f\"No JSON object found. Raw output:\\n{text}\")\n",
    "\n",
    "    return json.loads(text[start:end])\n",
    "\n",
    "\n",
    "def validate_classifier_output(obj: dict) -> None:\n",
    "    \"\"\"\n",
    "    Enforce strict contract for classifier:\n",
    "    - only keys: classification, reasoning\n",
    "    - classification in allowed set\n",
    "    \"\"\"\n",
    "    if not isinstance(obj, dict):\n",
    "        raise ValueError(\"Classifier output must be a JSON object.\")\n",
    "\n",
    "    allowed_keys = {\"classification\", \"reasoning\"}\n",
    "    extra = set(obj.keys()) - allowed_keys\n",
    "    missing = allowed_keys - set(obj.keys())\n",
    "\n",
    "    if missing:\n",
    "        raise ValueError(f\"Classifier JSON missing keys: {missing}\")\n",
    "    if extra:\n",
    "        raise ValueError(f\"Classifier JSON has extra keys (not allowed): {extra}\")\n",
    "\n",
    "    if obj[\"classification\"] not in {\"simple\", \"reasoning\", \"internet_search\"}:\n",
    "        raise ValueError(f\"Invalid classification: {obj['classification']}\")\n",
    "\n",
    "\n",
    "def validate_evidence_pack(obj: dict) -> None:\n",
    "    \"\"\"\n",
    "    Enforce strict contract for evidence pack.\n",
    "    \"\"\"\n",
    "    if not isinstance(obj, dict):\n",
    "        raise ValueError(\"Evidence pack must be a JSON object.\")\n",
    "\n",
    "    required = {\"key_facts\", \"likely_current_answer\", \"what_to_verify\", \"confidence_level\"}\n",
    "    missing = required - set(obj.keys())\n",
    "    if missing:\n",
    "        raise ValueError(f\"Evidence pack JSON missing keys: {missing}\")\n",
    "\n",
    "    if obj[\"confidence_level\"] not in {\"low\", \"medium\", \"high\"}:\n",
    "        raise ValueError(f\"Invalid confidence_level: {obj['confidence_level']}\")\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# End-to-end router\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "def run_prompt(user_prompt: str) -> dict:\n",
    "    # 1) classify\n",
    "    cls_msg = classification_chain.invoke({\"user_prompt\": user_prompt})\n",
    "    cls_obj = parse_json_message(cls_msg)\n",
    "    validate_classifier_output(cls_obj)\n",
    "\n",
    "    classification = cls_obj[\"classification\"]\n",
    "    routing_reason = cls_obj[\"reasoning\"]\n",
    "\n",
    "    # 2) evidence pack if needed\n",
    "    evidence_pack = None\n",
    "    if classification == \"internet_search\":\n",
    "        ev_msg = search_chain.invoke({\"user_prompt\": user_prompt})\n",
    "        evidence_pack = parse_json_message(ev_msg)\n",
    "        validate_evidence_pack(evidence_pack)\n",
    "\n",
    "    # 3) generate final response\n",
    "    final_answer = generate_response(\n",
    "        user_prompt=user_prompt,\n",
    "        classification=classification,\n",
    "        evidence_pack=evidence_pack\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"user_prompt\": user_prompt,\n",
    "        \"classification\": classification,\n",
    "        \"routing_reason\": routing_reason,\n",
    "        \"evidence_pack\": evidence_pack,\n",
    "        \"response\": final_answer\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"Router initialized: run_prompt(user_prompt)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "67d4656b-8f4f-4e70-80c2-4cd7809871ad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Enter a prompt:  what is p_value?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n================================================================================\nPROMPT: what is p_value?\n\nClassification: simple\nRouting reason: A p-value is a statistical measure of the probability of observing results at least as extreme as those observed during an experiment, assuming that the null hypothesis is true.\n\nResponse:\np_value is the probability of observing a result as extreme or more extreme than the one observed, assuming the null hypothesis is true.\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------------------------\n",
    "# Interactive runner\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "user_prompt = input(\"Enter a prompt: \").strip()\n",
    "\n",
    "result = run_prompt(user_prompt)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"PROMPT:\", result[\"user_prompt\"])\n",
    "\n",
    "print(\"\\nClassification:\", result[\"classification\"])\n",
    "print(\"Routing reason:\", result[\"routing_reason\"])\n",
    "\n",
    "if result[\"evidence_pack\"] is not None:\n",
    "    print(\"\\nEvidence pack:\")\n",
    "    print(json.dumps(result[\"evidence_pack\"], indent=2))\n",
    "\n",
    "print(\"\\nResponse:\")\n",
    "print(result[\"response\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2e202469-1978-4346-ba48-7009f3267587",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "099d5219-d862-4f13-9a69-2ae4ac8c62f2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from dataclasses import dataclass\n",
    "from typing import Callable, Dict, Any, Optional\n",
    "\n",
    "# LangChain\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# Databricks LLM\n",
    "from databricks_langchain import ChatDatabricks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9d56d0e0-1943-4aa6-9a3e-5c64c8f2f34f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized LLM endpoint: databricks-meta-llama-3-1-8b-instruct\nRoles: classifier_llm, simple_llm, reasoning_llm, search_llm\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------------------------\n",
    "# LLM instances by role (enterprise pattern)\n",
    "# -------------------------------------------------------------------\n",
    "classifier_llm = ChatDatabricks(endpoint=LLM_ENDPOINT_NAME, temperature=0.0)  # deterministic routing\n",
    "simple_llm     = ChatDatabricks(endpoint=LLM_ENDPOINT_NAME, temperature=0.2)\n",
    "reasoning_llm  = ChatDatabricks(endpoint=LLM_ENDPOINT_NAME, temperature=0.2)\n",
    "search_llm     = ChatDatabricks(endpoint=LLM_ENDPOINT_NAME, temperature=0.2)\n",
    "\n",
    "print(\"Initialized LLM endpoint:\", LLM_ENDPOINT_NAME)\n",
    "print(\"Roles: classifier_llm, simple_llm, reasoning_llm, search_llm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e7f142d-c5ac-489e-adac-e8f167d9df30",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent abstraction ready.\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class Agent:\n",
    "    \"\"\"\n",
    "    Lightweight agent abstraction (Databricks-native).\n",
    "    Each agent exposes a `run()` callable that returns a structured dict output.\n",
    "    \"\"\"\n",
    "    name: str\n",
    "    description: str\n",
    "    run: Callable[..., Dict[str, Any]]\n",
    "\n",
    "\n",
    "# Registry placeholder (we'll fill this after defining agents)\n",
    "AGENTS: Dict[str, Agent] = {}\n",
    "\n",
    "print(\"Agent abstraction ready.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1a6052bb-3965-4719-93c5-96063cf25181",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON parsing + validation utilities ready.\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------------------------\n",
    "# Robust JSON extraction from LLM messages\n",
    "# -------------------------------------------------------------------\n",
    "def parse_json_message(msg) -> dict:\n",
    "    \"\"\"\n",
    "    Extract the first JSON object from an LLM message.\n",
    "    Fails fast if no valid JSON object is found.\n",
    "    \"\"\"\n",
    "    text = msg.content if hasattr(msg, \"content\") else str(msg)\n",
    "    text = text.strip()\n",
    "\n",
    "    # Remove accidental code fences\n",
    "    if text.startswith(\"```\"):\n",
    "        text = text.strip(\"`\").strip()\n",
    "\n",
    "    start = text.find(\"{\")\n",
    "    end = text.rfind(\"}\") + 1\n",
    "    if start == -1 or end <= start:\n",
    "        raise ValueError(f\"No JSON object found. Raw output:\\n{text}\")\n",
    "\n",
    "    return json.loads(text[start:end])\n",
    "\n",
    "\n",
    "def validate_classifier_output(obj: dict) -> None:\n",
    "    \"\"\"\n",
    "    Enforce strict classifier contract:\n",
    "    - only keys: classification, reasoning\n",
    "    - classification in allowed set\n",
    "    \"\"\"\n",
    "    if not isinstance(obj, dict):\n",
    "        raise ValueError(\"Classifier output must be a JSON object.\")\n",
    "\n",
    "    allowed_keys = {\"classification\", \"reasoning\"}\n",
    "    extra = set(obj.keys()) - allowed_keys\n",
    "    missing = allowed_keys - set(obj.keys())\n",
    "\n",
    "    if missing:\n",
    "        raise ValueError(f\"Classifier JSON missing keys: {missing}\")\n",
    "    if extra:\n",
    "        raise ValueError(f\"Classifier JSON has extra keys (not allowed): {extra}\")\n",
    "\n",
    "    if obj[\"classification\"] not in {\"simple\", \"reasoning\", \"internet_search\"}:\n",
    "        raise ValueError(f\"Invalid classification: {obj['classification']}\")\n",
    "\n",
    "\n",
    "def validate_evidence_pack(obj: dict) -> None:\n",
    "    \"\"\"\n",
    "    Enforce strict evidence pack contract.\n",
    "    \"\"\"\n",
    "    if not isinstance(obj, dict):\n",
    "        raise ValueError(\"Evidence pack must be a JSON object.\")\n",
    "\n",
    "    required = {\"key_facts\", \"likely_current_answer\", \"what_to_verify\", \"confidence_level\"}\n",
    "    missing = required - set(obj.keys())\n",
    "    if missing:\n",
    "        raise ValueError(f\"Evidence pack JSON missing keys: {missing}\")\n",
    "\n",
    "    if obj[\"confidence_level\"] not in {\"low\", \"medium\", \"high\"}:\n",
    "        raise ValueError(f\"Invalid confidence_level: {obj['confidence_level']}\")\n",
    "\n",
    "\n",
    "print(\"JSON parsing + validation utilities ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fb412771-dae2-4a3c-b2d3-21efc675e781",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running tests...\n\nOK (classifier missing key): Classifier JSON missing keys: {'reasoning'}\nOK (classifier extra key): Classifier JSON has extra keys (not allowed): {'extra'}\nOK (classifier invalid label): Invalid classification: unknown\nOK (evidence missing keys): Evidence pack JSON missing keys: {'confidence_level', 'what_to_verify', 'likely_current_answer'}\nOK (evidence invalid confidence_level): Invalid confidence_level: certain\n\nAll tests passed ✅\n"
     ]
    }
   ],
   "source": [
    "# Minimal stub to mimic LangChain message objects with .content\n",
    "class FakeMsg:\n",
    "    def __init__(self, content: str):\n",
    "        self.content = content\n",
    "\n",
    "def run_tests():\n",
    "    print(\"Running tests...\\n\")\n",
    "\n",
    "    # -------------------------\n",
    "    # parse_json_message tests\n",
    "    # -------------------------\n",
    "    msg1 = FakeMsg('{\"classification\":\"simple\",\"reasoning\":\"Direct definition.\"}')\n",
    "    assert parse_json_message(msg1)[\"classification\"] == \"simple\"\n",
    "\n",
    "    msg2 = FakeMsg('```json\\n{\"classification\":\"reasoning\",\"reasoning\":\"Needs steps.\"}\\n```')\n",
    "    assert parse_json_message(msg2)[\"classification\"] == \"reasoning\"\n",
    "\n",
    "    msg3 = FakeMsg('Some text before\\n{\"classification\":\"internet_search\",\"reasoning\":\"Needs fresh info.\"}\\nSome text after')\n",
    "    assert parse_json_message(msg3)[\"classification\"] == \"internet_search\"\n",
    "\n",
    "    # -------------------------\n",
    "    # validate_classifier_output tests\n",
    "    # -------------------------\n",
    "    good_cls = {\"classification\": \"simple\", \"reasoning\": \"Direct.\"}\n",
    "    validate_classifier_output(good_cls)\n",
    "\n",
    "    try:\n",
    "        validate_classifier_output({\"classification\": \"simple\"})  # missing reasoning\n",
    "        raise AssertionError(\"Expected missing key error for classifier\")\n",
    "    except ValueError as e:\n",
    "        print(\"OK (classifier missing key):\", e)\n",
    "\n",
    "    try:\n",
    "        validate_classifier_output({\"classification\": \"simple\", \"reasoning\": \"x\", \"extra\": 1})\n",
    "        raise AssertionError(\"Expected extra key error for classifier\")\n",
    "    except ValueError as e:\n",
    "        print(\"OK (classifier extra key):\", e)\n",
    "\n",
    "    try:\n",
    "        validate_classifier_output({\"classification\": \"unknown\", \"reasoning\": \"x\"})\n",
    "        raise AssertionError(\"Expected invalid classification error\")\n",
    "    except ValueError as e:\n",
    "        print(\"OK (classifier invalid label):\", e)\n",
    "\n",
    "    # -------------------------\n",
    "    # validate_evidence_pack tests\n",
    "    # -------------------------\n",
    "    good_ev = {\n",
    "        \"key_facts\": [\"A\", \"B\"],\n",
    "        \"likely_current_answer\": \"May be outdated.\",\n",
    "        \"what_to_verify\": [\"Verify with BLS.\"],\n",
    "        \"confidence_level\": \"low\"\n",
    "    }\n",
    "    validate_evidence_pack(good_ev)\n",
    "\n",
    "    try:\n",
    "        validate_evidence_pack({\"key_facts\": []})  # missing most fields\n",
    "        raise AssertionError(\"Expected missing key error for evidence pack\")\n",
    "    except ValueError as e:\n",
    "        print(\"OK (evidence missing keys):\", e)\n",
    "\n",
    "    try:\n",
    "        bad_ev = {\n",
    "            \"key_facts\": [],\n",
    "            \"likely_current_answer\": \"\",\n",
    "            \"what_to_verify\": [],\n",
    "            \"confidence_level\": \"certain\"  # invalid\n",
    "        }\n",
    "        validate_evidence_pack(bad_ev)\n",
    "        raise AssertionError(\"Expected invalid confidence_level error\")\n",
    "    except ValueError as e:\n",
    "        print(\"OK (evidence invalid confidence_level):\", e)\n",
    "\n",
    "    print(\"\\nAll tests passed ✅\")\n",
    "\n",
    "run_tests()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cfd67c86-8380-407e-a1d0-cd13894cdb43",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RouterAgent registered as AGENTS['router']\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------------------------\n",
    "# Router prompt (STRICT JSON) — remember to escape braces for LangChain\n",
    "# -------------------------------------------------------------------\n",
    "router_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "You are an enterprise routing controller.\n",
    "\n",
    "Classify the user prompt into EXACTLY ONE category:\n",
    "- simple\n",
    "- reasoning\n",
    "- internet_search\n",
    "\n",
    "Definitions:\n",
    "- simple: directly answerable; no multi-step reasoning; no fresh data needed\n",
    "- reasoning: requires multi-step logic, comparison, synthesis, or structured thought\n",
    "- internet_search: requires up-to-date or externally verifiable information\n",
    "\n",
    "Hard rules:\n",
    "- Return STRICT JSON only (no markdown, no extra text)\n",
    "- Use ONLY the two keys: classification, reasoning\n",
    "- classification must be exactly one of: \"simple\", \"reasoning\", \"internet_search\"\n",
    "- reasoning must be a short sentence\n",
    "\n",
    "User prompt:\n",
    "{user_prompt}\n",
    "\n",
    "Return JSON:\n",
    "{{\n",
    "  \"classification\": \"simple | reasoning | internet_search\",\n",
    "  \"reasoning\": \"...\"\n",
    "}}\n",
    "\"\"\")\n",
    "\n",
    "router_chain = router_prompt | classifier_llm\n",
    "\n",
    "\n",
    "def router_agent_run(user_prompt: str) -> Dict[str, Any]:\n",
    "    msg = router_chain.invoke({\"user_prompt\": user_prompt})\n",
    "    obj = parse_json_message(msg)\n",
    "    validate_classifier_output(obj)\n",
    "    return obj  # {\"classification\": ..., \"reasoning\": ...}\n",
    "\n",
    "\n",
    "RouterAgent = Agent(\n",
    "    name=\"RouterAgent\",\n",
    "    description=\"Deterministic router that classifies prompts into simple/reasoning/internet_search.\",\n",
    "    run=router_agent_run\n",
    ")\n",
    "\n",
    "AGENTS[\"router\"] = RouterAgent\n",
    "\n",
    "print(\"RouterAgent registered as AGENTS['router']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d01de646-250f-4d32-9846-98c08b943c6b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleAgent registered as AGENTS['simple']\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------------------------\n",
    "# SimpleAgent prompt\n",
    "# -------------------------------------------------------------------\n",
    "simple_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "Answer the question directly and concisely.\n",
    "\n",
    "Question:\n",
    "{user_prompt}\n",
    "\"\"\")\n",
    "\n",
    "simple_chain = simple_prompt | simple_llm\n",
    "\n",
    "\n",
    "def simple_agent_run(user_prompt: str) -> Dict[str, Any]:\n",
    "    msg = simple_chain.invoke({\"user_prompt\": user_prompt})\n",
    "    return {\"response\": msg.content}\n",
    "\n",
    "\n",
    "SimpleAgent = Agent(\n",
    "    name=\"SimpleAgent\",\n",
    "    description=\"Fast and efficient agent for straightforward questions.\",\n",
    "    run=simple_agent_run\n",
    ")\n",
    "\n",
    "AGENTS[\"simple\"] = SimpleAgent\n",
    "\n",
    "print(\"SimpleAgent registered as AGENTS['simple']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "76838dde-0187-4fc1-a8cd-c7d33cf637b0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReasoningAgent registered as AGENTS['reasoning']\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------------------------\n",
    "# ReasoningAgent prompt\n",
    "# -------------------------------------------------------------------\n",
    "reasoning_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "Answer the question using clear, step-by-step reasoning.\n",
    "Structure your answer logically and avoid unnecessary verbosity.\n",
    "\n",
    "Question:\n",
    "{user_prompt}\n",
    "\"\"\")\n",
    "\n",
    "reasoning_chain = reasoning_prompt | reasoning_llm\n",
    "\n",
    "\n",
    "def reasoning_agent_run(user_prompt: str) -> Dict[str, Any]:\n",
    "    msg = reasoning_chain.invoke({\"user_prompt\": user_prompt})\n",
    "    return {\"response\": msg.content}\n",
    "\n",
    "\n",
    "ReasoningAgent = Agent(\n",
    "    name=\"ReasoningAgent\",\n",
    "    description=\"Handles prompts requiring multi-step reasoning or synthesis.\",\n",
    "    run=reasoning_agent_run\n",
    ")\n",
    "\n",
    "AGENTS[\"reasoning\"] = ReasoningAgent\n",
    "\n",
    "print(\"ReasoningAgent registered as AGENTS['reasoning']\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d5a04b06-f451-4fa7-9e9a-f8808197ca9e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SearchAgent registered ✅\nRegistered agents now: ['internet_search', 'reasoning', 'router', 'simple']\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------------------------\n",
    "# SearchAgent (Evidence Pack + Synthesis, No External APIs) — retry\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "evidence_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "You are a research assistant operating WITHOUT web access.\n",
    "\n",
    "The question requires up-to-date or externally verifiable information.\n",
    "Generate a structured evidence pack to help answer it.\n",
    "\n",
    "Rules:\n",
    "- Do NOT claim real-time access\n",
    "- Clearly mark uncertainty\n",
    "- Be concise and factual\n",
    "- Return STRICT JSON only\n",
    "- Do NOT include markdown or extra text\n",
    "\n",
    "User question:\n",
    "{user_prompt}\n",
    "\n",
    "Return JSON in this exact format:\n",
    "{{\n",
    "  \"key_facts\": [\n",
    "    \"Important factual points relevant to the question\"\n",
    "  ],\n",
    "  \"likely_current_answer\": \"Best estimate based on general knowledge (may be outdated)\",\n",
    "  \"what_to_verify\": [\n",
    "    \"What a human should verify using an authoritative source\"\n",
    "  ],\n",
    "  \"confidence_level\": \"low | medium | high\"\n",
    "}}\n",
    "\"\"\")\n",
    "\n",
    "evidence_chain = evidence_prompt | search_llm\n",
    "\n",
    "\n",
    "synthesis_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "You do NOT have web access. Use the evidence pack below to answer.\n",
    "Be explicit about uncertainty and what should be verified.\n",
    "\n",
    "Evidence pack (JSON):\n",
    "{evidence_pack}\n",
    "\n",
    "Question:\n",
    "{user_prompt}\n",
    "\n",
    "Answer:\n",
    "\"\"\")\n",
    "\n",
    "synthesis_chain = synthesis_prompt | search_llm\n",
    "\n",
    "\n",
    "def search_agent_run(user_prompt: str) -> Dict[str, Any]:\n",
    "    ev_msg = evidence_chain.invoke({\"user_prompt\": user_prompt})\n",
    "    evidence_pack = parse_json_message(ev_msg)\n",
    "    validate_evidence_pack(evidence_pack)\n",
    "\n",
    "    synth_msg = synthesis_chain.invoke({\n",
    "        \"user_prompt\": user_prompt,\n",
    "        \"evidence_pack\": json.dumps(evidence_pack, ensure_ascii=False, indent=2),\n",
    "    })\n",
    "\n",
    "    return {\"evidence_pack\": evidence_pack, \"response\": synth_msg.content}\n",
    "\n",
    "\n",
    "SearchAgent = Agent(\n",
    "    name=\"SearchAgent\",\n",
    "    description=\"Generates a prompt-based evidence pack (no web) and synthesizes an answer with uncertainty + verification steps.\",\n",
    "    run=search_agent_run\n",
    ")\n",
    "\n",
    "AGENTS[\"internet_search\"] = SearchAgent\n",
    "\n",
    "print(\"SearchAgent registered ✅\")\n",
    "print(\"Registered agents now:\", sorted(AGENTS.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a8fb0bc3-cea1-4b6a-9051-f756cc3e3562",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orchestrator ready ✅  Use: run_prompt_with_agents(user_prompt)\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------------------------\n",
    "# Orchestrator: router -> dispatch to specialized agent\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "AGENT_MAP = {\n",
    "    \"simple\": AGENTS[\"simple\"],\n",
    "    \"reasoning\": AGENTS[\"reasoning\"],\n",
    "    \"internet_search\": AGENTS[\"internet_search\"],\n",
    "}\n",
    "\n",
    "def run_prompt_with_agents(user_prompt: str) -> Dict[str, Any]:\n",
    "    # 1) Route\n",
    "    route = AGENTS[\"router\"].run(user_prompt)\n",
    "    classification = route[\"classification\"]\n",
    "    routing_reason = route[\"reasoning\"]\n",
    "\n",
    "    # 2) Dispatch\n",
    "    if classification not in AGENT_MAP:\n",
    "        raise ValueError(f\"No agent registered for classification: {classification}\")\n",
    "\n",
    "    agent = AGENT_MAP[classification]\n",
    "    out = agent.run(user_prompt)\n",
    "\n",
    "    # 3) Structured result (good for logging / observability)\n",
    "    return {\n",
    "        \"user_prompt\": user_prompt,\n",
    "        \"classification\": classification,\n",
    "        \"routing_reason\": routing_reason,\n",
    "        \"agent_used\": agent.name,\n",
    "        **out,\n",
    "    }\n",
    "\n",
    "print(\"Orchestrator ready ✅  Use: run_prompt_with_agents(user_prompt)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c2d8111e-cd7b-431e-aaea-884a141ca986",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n==========================================================================================\nExpected: simple\nPrompt: What is a p-value?\n\nClassification: simple\nAgent used: SimpleAgent\nRouting reason: A p-value is a statistical measure of the probability of observing results at least as extreme as those observed during the experiment, assuming that the null hypothesis is true.\n\nResponse:\n The p-value is the probability of observing a result as extreme or more extreme than the one observed, assuming the null hypothesis is true.\n\n==========================================================================================\nExpected: reasoning\nPrompt: If precision is high but recall is low, what does that imply? Give an example.\n\nClassification: simple\nAgent used: SimpleAgent\nRouting reason: It implies that the model is good at making correct predictions, but misses many actual instances.\n\nResponse:\n It implies that the model is good at making correct predictions (high precision) but misses many actual instances (low recall). Example: A medical test that correctly identifies 90% of cancer patients (high precision) but misses 70% of actual cancer cases (low recall).\n\n==========================================================================================\nExpected: internet_search\nPrompt: What is the current inflation rate in the US?\n\nClassification: internet_search\nAgent used: SearchAgent\nRouting reason: This question requires access to current and up-to-date economic data to provide an accurate answer.\n\nEvidence pack:\n{\n  \"key_facts\": [\n    \"The US inflation rate is typically measured by the Consumer Price Index (CPI)\",\n    \"The CPI is a basket of goods and services that tracks price changes over time\",\n    \"Inflation rates can vary by region and over time\"\n  ],\n  \"likely_current_answer\": \"Around 2-3% (based on 2020 data, which may not reflect current rates)\",\n  \"what_to_verify\": [\n    \"Check the latest CPI data from the Bureau of Labor Statistics (BLS)\",\n    \"Verify the current inflation rate with a reliable news source or economic publication\"\n  ],\n  \"confidence_level\": \"low\"\n}\n\nResponse:\n Based on the evidence pack, I would answer:\n\nThe current inflation rate in the US is uncertain and likely to be around 2-3%, but this is based on 2020 data and may not reflect current rates. To determine the current inflation rate, it is recommended to check the latest CPI data from the Bureau of Labor Statistics (BLS) and verify the current inflation rate with a reliable news source or economic publication.\n\n**Uncertainty level: High**\n\n**Confidence level: Low**\n\n**Recommendations for verification:**\n\n1. Check the latest CPI data from the Bureau of Labor Statistics (BLS)\n2. Verify the current inflation rate with a reliable news source or economic publication\n\nPlease note that the current inflation rate is subject to change and may have been affected by various economic factors since 2020. Therefore, it is essential to verify the information with up-to-date sources to get an accurate answer.\n"
     ]
    }
   ],
   "source": [
    "tests = [\n",
    "    (\"simple\", \"What is a p-value?\"),\n",
    "    (\"reasoning\", \"If precision is high but recall is low, what does that imply? Give an example.\"),\n",
    "    (\"internet_search\", \"What is the current inflation rate in the US?\")\n",
    "]\n",
    "\n",
    "for expected, prompt in tests:\n",
    "    print(\"\\n\" + \"=\" * 90)\n",
    "    print(f\"Expected: {expected}\")\n",
    "    print(\"Prompt:\", prompt)\n",
    "\n",
    "    out = run_prompt_with_agents(prompt)\n",
    "\n",
    "    print(\"\\nClassification:\", out[\"classification\"])\n",
    "    print(\"Agent used:\", out[\"agent_used\"])\n",
    "    print(\"Routing reason:\", out[\"routing_reason\"])\n",
    "\n",
    "    if out[\"classification\"] == \"internet_search\":\n",
    "        print(\"\\nEvidence pack:\")\n",
    "        print(json.dumps(out[\"evidence_pack\"], indent=2))\n",
    "\n",
    "    print(\"\\nResponse:\\n\", out[\"response\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "555b813a-5cb1-4c8b-a676-02474133b6e0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event + InvocationContext ready ✅\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from typing import Any, Dict, Optional, AsyncGenerator\n",
    "\n",
    "@dataclass\n",
    "class Message:\n",
    "    role: str\n",
    "    text: str\n",
    "\n",
    "@dataclass\n",
    "class InvocationContext:\n",
    "    \"\"\"\n",
    "    Minimal ADK-like invocation context.\n",
    "    Holds the current message plus optional metadata (request_id, user_id, etc.).\n",
    "    \"\"\"\n",
    "    current_message: Message\n",
    "    metadata: Dict[str, Any] = field(default_factory=dict)\n",
    "\n",
    "@dataclass\n",
    "class Event:\n",
    "    \"\"\"\n",
    "    Minimal ADK-like event for observability.\n",
    "    \"\"\"\n",
    "    author: str\n",
    "    type: str  # e.g. \"route\", \"tool\", \"final\", \"debug\"\n",
    "    content: Any\n",
    "    metadata: Dict[str, Any] = field(default_factory=dict)\n",
    "\n",
    "print(\"Event + InvocationContext ready ✅\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "af2899f7-1aef-437a-b9ff-93202eaefa44",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AsyncBaseAgent + SyncAgentAdapter ready ✅\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import AsyncGenerator, Callable\n",
    "\n",
    "\n",
    "class AsyncBaseAgent(ABC):\n",
    "    \"\"\"\n",
    "    ADK-like async agent interface that yields Events.\n",
    "    \"\"\"\n",
    "\n",
    "    name: str = \"BaseAgent\"\n",
    "    description: str = \"\"\n",
    "\n",
    "    async def run(self, context: InvocationContext) -> AsyncGenerator[Event, None]:\n",
    "        async for ev in self.run_async_impl(context):\n",
    "            yield ev\n",
    "\n",
    "    @abstractmethod\n",
    "    async def run_async_impl(self, context: InvocationContext) -> AsyncGenerator[Event, None]:\n",
    "        ...\n",
    "\n",
    "\n",
    "async def _run_in_thread(fn: Callable, *args, **kwargs):\n",
    "    \"\"\"\n",
    "    Run sync functions without blocking the event loop.\n",
    "    Databricks notebooks are sync by default; this makes async composition possible.\n",
    "    \"\"\"\n",
    "    return await asyncio.to_thread(fn, *args, **kwargs)\n",
    "\n",
    "\n",
    "class SyncAgentAdapter(AsyncBaseAgent):\n",
    "    \"\"\"\n",
    "    Wraps an existing *sync* agent (our Agent dataclass with .run(user_prompt)->dict)\n",
    "    into an ADK-like async agent that yields Events.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, agent: Agent, event_type: str = \"final\"):\n",
    "        self._agent = agent\n",
    "        self.name = agent.name\n",
    "        self.description = agent.description\n",
    "        self._event_type = event_type\n",
    "\n",
    "    async def run_async_impl(self, context: InvocationContext) -> AsyncGenerator[Event, None]:\n",
    "        yield Event(\n",
    "            author=self.name,\n",
    "            type=\"debug\",\n",
    "            content=\"starting\",\n",
    "            metadata={\"agent\": self.name}\n",
    "        )\n",
    "\n",
    "        # Execute the underlying sync agent off-thread\n",
    "        out = await _run_in_thread(self._agent.run, context.current_message.text)\n",
    "\n",
    "        yield Event(\n",
    "            author=self.name,\n",
    "            type=self._event_type,\n",
    "            content=out,\n",
    "            metadata={\"agent\": self.name}\n",
    "        )\n",
    "\n",
    "\n",
    "print(\"AsyncBaseAgent + SyncAgentAdapter ready ✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c67d4960-e1be-4f23-b952-3a1b5e5efbc8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QueryRouterAgent ready ✅ (async, event-streaming)\n"
     ]
    }
   ],
   "source": [
    "class QueryRouterAgent(AsyncBaseAgent):\n",
    "    name: str = \"QueryRouter\"\n",
    "    description: str = \"Routes user queries to the appropriate agent based on classification (with optional heuristics).\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        router_agent: Agent,\n",
    "        simple_agent: Agent,\n",
    "        reasoning_agent: Agent,\n",
    "        search_agent: Agent,\n",
    "        *,\n",
    "        enable_length_fallback: bool = True,\n",
    "        short_query_word_threshold: int = 20,\n",
    "    ):\n",
    "        self.router_agent = router_agent\n",
    "        self.enable_length_fallback = enable_length_fallback\n",
    "        self.short_query_word_threshold = short_query_word_threshold\n",
    "\n",
    "        # Wrap sync agents into async, event-yielding agents\n",
    "        self.simple_async = SyncAgentAdapter(simple_agent, event_type=\"final\")\n",
    "        self.reasoning_async = SyncAgentAdapter(reasoning_agent, event_type=\"final\")\n",
    "        self.search_async = SyncAgentAdapter(search_agent, event_type=\"final\")\n",
    "\n",
    "    async def run_async_impl(self, context: InvocationContext) -> AsyncGenerator[Event, None]:\n",
    "        user_query = context.current_message.text\n",
    "        query_len = len(user_query.split())\n",
    "\n",
    "        # 1) Emit debug info\n",
    "        yield Event(\n",
    "            author=self.name,\n",
    "            type=\"debug\",\n",
    "            content={\"query_word_count\": query_len},\n",
    "            metadata={\"threshold\": self.short_query_word_threshold}\n",
    "        )\n",
    "\n",
    "        # 2) Try deterministic classification first (RouterAgent)\n",
    "        classification = None\n",
    "        routing_reason = None\n",
    "        try:\n",
    "            route_obj = await _run_in_thread(self.router_agent.run, user_query)\n",
    "            classification = route_obj[\"classification\"]\n",
    "            routing_reason = route_obj[\"reasoning\"]\n",
    "\n",
    "            yield Event(\n",
    "                author=self.name,\n",
    "                type=\"route\",\n",
    "                content={\"classification\": classification, \"reasoning\": routing_reason},\n",
    "            )\n",
    "\n",
    "        except Exception as e:\n",
    "            # Router failed (parse error, etc.)\n",
    "            yield Event(\n",
    "                author=self.name,\n",
    "                type=\"error\",\n",
    "                content=f\"RouterAgent failed; will {'use' if self.enable_length_fallback else 'not use'} fallback. Error: {e}\",\n",
    "            )\n",
    "\n",
    "            if not self.enable_length_fallback:\n",
    "                raise\n",
    "\n",
    "        # 3) Optional fallback heuristic if RouterAgent failed\n",
    "        if classification is None and self.enable_length_fallback:\n",
    "            # simple heuristic: short => simple, long => reasoning\n",
    "            classification = \"simple\" if query_len < self.short_query_word_threshold else \"reasoning\"\n",
    "            routing_reason = f\"Fallback heuristic used: word_count={query_len}, threshold={self.short_query_word_threshold}\"\n",
    "\n",
    "            yield Event(\n",
    "                author=self.name,\n",
    "                type=\"route\",\n",
    "                content={\"classification\": classification, \"reasoning\": routing_reason},\n",
    "                metadata={\"fallback\": True}\n",
    "            )\n",
    "\n",
    "        # 4) Dispatch to the chosen agent and stream its events\n",
    "        if classification == \"simple\":\n",
    "            async for ev in self.simple_async.run(context):\n",
    "                yield ev\n",
    "\n",
    "        elif classification == \"reasoning\":\n",
    "            async for ev in self.reasoning_async.run(context):\n",
    "                yield ev\n",
    "\n",
    "        elif classification == \"internet_search\":\n",
    "            async for ev in self.search_async.run(context):\n",
    "                yield ev\n",
    "\n",
    "        else:\n",
    "            yield Event(\n",
    "                author=self.name,\n",
    "                type=\"error\",\n",
    "                content=f\"Unknown classification: {classification}\",\n",
    "                metadata={\"classification\": classification}\n",
    "            )\n",
    "            raise ValueError(f\"Unknown classification: {classification}\")\n",
    "\n",
    "\n",
    "# Instantiate router with your existing agents from AGENTS registry\n",
    "query_router_agent = QueryRouterAgent(\n",
    "    router_agent=AGENTS[\"router\"],\n",
    "    simple_agent=AGENTS[\"simple\"],\n",
    "    reasoning_agent=AGENTS[\"reasoning\"],\n",
    "    search_agent=AGENTS[\"internet_search\"],\n",
    "    enable_length_fallback=True,\n",
    "    short_query_word_threshold=20\n",
    ")\n",
    "\n",
    "print(\"QueryRouterAgent ready ✅ (async, event-streaming)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1f7383a7-348a-4b41-9c39-d4a5d937fd72",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook-safe runner ready ✅  Use: await run_agent_async('your question')\n"
     ]
    }
   ],
   "source": [
    "async def run_with_events(user_text: str):\n",
    "    ctx = InvocationContext(current_message=Message(role=\"user\", text=user_text))\n",
    "\n",
    "    events = []\n",
    "    async for ev in query_router_agent.run(ctx):\n",
    "        events.append(ev)\n",
    "\n",
    "    return events\n",
    "\n",
    "\n",
    "def pretty_print_events(events):\n",
    "    print(\"\\n\" + \"=\" * 90)\n",
    "    for i, ev in enumerate(events, 1):\n",
    "        print(f\"[{i}] {ev.type.upper()}  | author={ev.author}\")\n",
    "        if ev.metadata:\n",
    "            print(\"    metadata:\", ev.metadata)\n",
    "        print(\"    content:\", ev.content)\n",
    "        print(\"-\" * 90)\n",
    "\n",
    "\n",
    "async def run_agent_async(user_text: str):\n",
    "    ctx = InvocationContext(current_message=Message(role=\"user\", text=user_text))\n",
    "\n",
    "    events = []\n",
    "    async for ev in query_router_agent.run(ctx):\n",
    "        events.append(ev)\n",
    "\n",
    "    # pretty print\n",
    "    print(\"\\n\" + \"=\" * 90)\n",
    "    for i, ev in enumerate(events, 1):\n",
    "        print(f\"[{i}] {ev.type.upper()}  | author={ev.author}\")\n",
    "        if ev.metadata:\n",
    "            print(\"    metadata:\", ev.metadata)\n",
    "        print(\"    content:\", ev.content)\n",
    "        print(\"-\" * 90)\n",
    "\n",
    "    return events\n",
    "\n",
    "\n",
    "print(\"Notebook-safe runner ready ✅  Use: await run_agent_async('your question')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6c827eee-4a57-46ac-84a8-26976264448a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n==========================================================================================\n[1] DEBUG  | author=QueryRouter\n    metadata: {'threshold': 20}\n    content: {'query_word_count': 4}\n------------------------------------------------------------------------------------------\n[2] ROUTE  | author=QueryRouter\n    content: {'classification': 'simple', 'reasoning': 'A p-value is a statistical measure of the probability of observing results at least as extreme as those observed during the experiment, assuming that the null hypothesis is true.'}\n------------------------------------------------------------------------------------------\n[3] DEBUG  | author=SimpleAgent\n    metadata: {'agent': 'SimpleAgent'}\n    content: starting\n------------------------------------------------------------------------------------------\n[4] FINAL  | author=SimpleAgent\n    metadata: {'agent': 'SimpleAgent'}\n    content: {'response': 'A p-value is the probability of observing a result at least as extreme as the one observed, assuming the null hypothesis is true.'}\n------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "events = await run_agent_async(\"What is a p-value?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "34282471-ce17-44df-a549-b4c234dc6333",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result extractor ready ✅  Use: result = await run_and_extract('...')\n"
     ]
    }
   ],
   "source": [
    "from time import perf_counter\n",
    "\n",
    "def extract_result_from_events(events):\n",
    "    \"\"\"\n",
    "    Convert an event stream into a clean result dict:\n",
    "      - classification\n",
    "      - routing_reason\n",
    "      - agent_used\n",
    "      - response\n",
    "      - evidence_pack (if any)\n",
    "    \"\"\"\n",
    "    result = {\n",
    "        \"classification\": None,\n",
    "        \"routing_reason\": None,\n",
    "        \"agent_used\": None,\n",
    "        \"response\": None,\n",
    "        \"evidence_pack\": None,\n",
    "    }\n",
    "\n",
    "    # routing info\n",
    "    for ev in events:\n",
    "        if ev.type == \"route\" and isinstance(ev.content, dict):\n",
    "            result[\"classification\"] = ev.content.get(\"classification\")\n",
    "            result[\"routing_reason\"] = ev.content.get(\"reasoning\")\n",
    "\n",
    "    # final output from specialist agent\n",
    "    for ev in reversed(events):\n",
    "        if ev.type == \"final\" and isinstance(ev.content, dict):\n",
    "            result[\"agent_used\"] = ev.author\n",
    "            # SearchAgent returns {\"evidence_pack\": ..., \"response\": ...}\n",
    "            if \"response\" in ev.content:\n",
    "                result[\"response\"] = ev.content[\"response\"]\n",
    "            if \"evidence_pack\" in ev.content:\n",
    "                result[\"evidence_pack\"] = ev.content[\"evidence_pack\"]\n",
    "            break\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "async def run_and_extract(user_text: str):\n",
    "    \"\"\"\n",
    "    Convenience wrapper: run QueryRouterAgent and return the cleaned result dict.\n",
    "    \"\"\"\n",
    "    events = await run_agent_async(user_text)\n",
    "    return extract_result_from_events(events)\n",
    "\n",
    "\n",
    "print(\"Result extractor ready ✅  Use: result = await run_and_extract('...')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3d651c88-d88a-4bb1-ad8a-a9c39cee89aa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n==========================================================================================\n[1] DEBUG  | author=QueryRouter\n    metadata: {'threshold': 20}\n    content: {'query_word_count': 4}\n------------------------------------------------------------------------------------------\n[2] ROUTE  | author=QueryRouter\n    content: {'classification': 'simple', 'reasoning': 'A p-value is a statistical measure of the probability of observing results at least as extreme as those observed during the experiment, assuming that the null hypothesis is true.'}\n------------------------------------------------------------------------------------------\n[3] DEBUG  | author=SimpleAgent\n    metadata: {'agent': 'SimpleAgent'}\n    content: starting\n------------------------------------------------------------------------------------------\n[4] FINAL  | author=SimpleAgent\n    metadata: {'agent': 'SimpleAgent'}\n    content: {'response': 'The p-value is the probability of observing a result as extreme or more extreme than the one observed, assuming that the null hypothesis is true.'}\n------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'classification': 'simple',\n",
       " 'routing_reason': 'A p-value is a statistical measure of the probability of observing results at least as extreme as those observed during the experiment, assuming that the null hypothesis is true.',\n",
       " 'agent_used': 'SimpleAgent',\n",
       " 'response': 'The p-value is the probability of observing a result as extreme or more extreme than the one observed, assuming that the null hypothesis is true.',\n",
       " 'evidence_pack': None}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = await run_and_extract(\"What is a p-value?\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "70c68c3a-efc7-4681-95e6-0e5a14f3369f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timed router ready ✅  Use: events = await run_agent_async_timed('...')\n"
     ]
    }
   ],
   "source": [
    "class TimedQueryRouterAgent(QueryRouterAgent):\n",
    "    \"\"\"\n",
    "    Same as QueryRouterAgent, but emits timing events.\n",
    "    \"\"\"\n",
    "\n",
    "    async def run_async_impl(self, context: InvocationContext) -> AsyncGenerator[Event, None]:\n",
    "        user_query = context.current_message.text\n",
    "        query_len = len(user_query.split())\n",
    "\n",
    "        yield Event(\n",
    "            author=self.name,\n",
    "            type=\"debug\",\n",
    "            content={\"query_word_count\": query_len},\n",
    "            metadata={\"threshold\": self.short_query_word_threshold}\n",
    "        )\n",
    "\n",
    "        # ---- Routing timing ----\n",
    "        t0 = perf_counter()\n",
    "        classification = None\n",
    "        routing_reason = None\n",
    "\n",
    "        try:\n",
    "            route_obj = await _run_in_thread(self.router_agent.run, user_query)\n",
    "            classification = route_obj[\"classification\"]\n",
    "            routing_reason = route_obj[\"reasoning\"]\n",
    "        finally:\n",
    "            t1 = perf_counter()\n",
    "            yield Event(\n",
    "                author=self.name,\n",
    "                type=\"timing\",\n",
    "                content={\"stage\": \"routing\", \"seconds\": round(t1 - t0, 4)}\n",
    "            )\n",
    "\n",
    "        yield Event(\n",
    "            author=self.name,\n",
    "            type=\"route\",\n",
    "            content={\"classification\": classification, \"reasoning\": routing_reason},\n",
    "        )\n",
    "\n",
    "        # ---- Dispatch timing ----\n",
    "        t2 = perf_counter()\n",
    "        try:\n",
    "            if classification == \"simple\":\n",
    "                async for ev in self.simple_async.run(context):\n",
    "                    yield ev\n",
    "            elif classification == \"reasoning\":\n",
    "                async for ev in self.reasoning_async.run(context):\n",
    "                    yield ev\n",
    "            elif classification == \"internet_search\":\n",
    "                async for ev in self.search_async.run(context):\n",
    "                    yield ev\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown classification: {classification}\")\n",
    "        finally:\n",
    "            t3 = perf_counter()\n",
    "            yield Event(\n",
    "                author=self.name,\n",
    "                type=\"timing\",\n",
    "                content={\"stage\": \"dispatch_total\", \"seconds\": round(t3 - t2, 4)},\n",
    "                metadata={\"classification\": classification}\n",
    "            )\n",
    "\n",
    "\n",
    "# Replace the router with the timed version (same config)\n",
    "timed_query_router_agent = TimedQueryRouterAgent(\n",
    "    router_agent=AGENTS[\"router\"],\n",
    "    simple_agent=AGENTS[\"simple\"],\n",
    "    reasoning_agent=AGENTS[\"reasoning\"],\n",
    "    search_agent=AGENTS[\"internet_search\"],\n",
    "    enable_length_fallback=True,\n",
    "    short_query_word_threshold=20\n",
    ")\n",
    "\n",
    "# Update runner to use timed agent\n",
    "async def run_agent_async_timed(user_text: str):\n",
    "    ctx = InvocationContext(current_message=Message(role=\"user\", text=user_text))\n",
    "\n",
    "    events = []\n",
    "    async for ev in timed_query_router_agent.run(ctx):\n",
    "        events.append(ev)\n",
    "\n",
    "    # pretty print\n",
    "    print(\"\\n\" + \"=\" * 90)\n",
    "    for i, ev in enumerate(events, 1):\n",
    "        print(f\"[{i}] {ev.type.upper()}  | author={ev.author}\")\n",
    "        if ev.metadata:\n",
    "            print(\"    metadata:\", ev.metadata)\n",
    "        print(\"    content:\", ev.content)\n",
    "        print(\"-\" * 90)\n",
    "\n",
    "    return events\n",
    "\n",
    "\n",
    "print(\"Timed router ready ✅  Use: events = await run_agent_async_timed('...')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "595252b9-671e-4858-ad06-aa261a09569a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n==========================================================================================\n[1] DEBUG  | author=QueryRouter\n    metadata: {'threshold': 20}\n    content: {'query_word_count': 9}\n------------------------------------------------------------------------------------------\n[2] TIMING  | author=QueryRouter\n    content: {'stage': 'routing', 'seconds': 0.5534}\n------------------------------------------------------------------------------------------\n[3] ROUTE  | author=QueryRouter\n    content: {'classification': 'internet_search', 'reasoning': 'This question requires access to current and up-to-date economic data to provide an accurate answer.'}\n------------------------------------------------------------------------------------------\n[4] DEBUG  | author=SearchAgent\n    metadata: {'agent': 'SearchAgent'}\n    content: starting\n------------------------------------------------------------------------------------------\n[5] FINAL  | author=SearchAgent\n    metadata: {'agent': 'SearchAgent'}\n    content: {'evidence_pack': {'key_facts': ['The US inflation rate is typically measured by the Consumer Price Index (CPI)', 'The CPI is published by the Bureau of Labor Statistics (BLS)', 'Inflation rates can vary by region and over time'], 'likely_current_answer': 'Around 2-3% (based on general knowledge of historical trends)', 'what_to_verify': ['Check the latest CPI data on the BLS website or other authoritative sources', 'Verify the current inflation rate as of the last available data point'], 'confidence_level': 'low'}, 'response': 'Based on the evidence pack, I would say that the current inflation rate in the US is uncertain and should be verified.\\n\\nAccording to the evidence pack, the likely current answer is \"Around 2-3% (based on general knowledge of historical trends)\", but this is based on general knowledge and not on the latest data. The confidence level is also listed as \"low\", which suggests that the answer is not reliable.\\n\\nTo get a more accurate answer, I would recommend verifying the current inflation rate as of the last available data point, as suggested in the \"what_to_verify\" section of the evidence pack. This would involve checking the latest CPI data on the BLS website or other authoritative sources.\\n\\nTherefore, my answer would be:\\n\\n\"The current inflation rate in the US is uncertain and should be verified. The likely current answer is around 2-3%, but this is based on general knowledge and not on the latest data. To get a more accurate answer, check the latest CPI data on the BLS website or other authoritative sources.\"'}\n------------------------------------------------------------------------------------------\n[6] TIMING  | author=QueryRouter\n    metadata: {'classification': 'internet_search'}\n    content: {'stage': 'dispatch_total', 'seconds': 2.1}\n------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "events = await run_agent_async_timed(\"What is the current inflation rate in the US?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "09dc39eb-76c8-498a-9620-af48bf4ba2e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CriticAgent patched ✅ (extra keys ignored)\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------------------------\n",
    "# CriticAgent prompt (STRICT JSON) — escape braces\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "CRITIC_SYSTEM_PROMPT = \"\"\"\n",
    "You are the **Critic Agent**, serving as the quality assurance arm of our collaborative assistant system.\n",
    "Your primary function is to meticulously review and challenge information from the answer-generating agent,\n",
    "guaranteeing accuracy, completeness, and unbiased presentation.\n",
    "\n",
    "Your duties:\n",
    "- Assess findings for factual correctness, thoroughness, and potential bias.\n",
    "- Identify missing data, assumptions, or inconsistencies in reasoning.\n",
    "- Raise critical questions that could refine or expand understanding.\n",
    "- Offer constructive suggestions for improvement or alternative angles.\n",
    "- Validate that the final output is comprehensive and balanced.\n",
    "\n",
    "All criticism must be constructive. Your goal is to fortify the work, not invalidate it.\n",
    "\n",
    "Return STRICT JSON only. No markdown. No extra keys.\n",
    "\"\"\"\n",
    "\n",
    "critic_prompt = ChatPromptTemplate.from_template(\n",
    "    CRITIC_SYSTEM_PROMPT\n",
    "    + \"\"\"\n",
    "\n",
    "Review the following assistant output.\n",
    "\n",
    "User prompt:\n",
    "{user_prompt}\n",
    "\n",
    "Routing classification:\n",
    "{classification}\n",
    "\n",
    "Evidence pack (may be null):\n",
    "{evidence_pack}\n",
    "\n",
    "Assistant draft answer:\n",
    "{draft_answer}\n",
    "\n",
    "Return JSON in this exact format:\n",
    "{{\n",
    "  \"verdict\": \"pass | needs_revision\",\n",
    "  \"major_issues\": [\"...\"],\n",
    "  \"minor_issues\": [\"...\"],\n",
    "  \"missing_info_questions\": [\"...\"],\n",
    "  \"suggested_improvements\": [\"...\"]\n",
    "}}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "critic_chain = critic_prompt | reasoning_llm  # can switch to a stronger endpoint later\n",
    "\n",
    "\n",
    "def critic_agent_run(\n",
    "    user_prompt: str,\n",
    "    classification: str,\n",
    "    draft_answer: str,\n",
    "    evidence_pack: Optional[dict] = None\n",
    ") -> Dict[str, Any]:\n",
    "    msg = critic_chain.invoke({\n",
    "        \"user_prompt\": user_prompt,\n",
    "        \"classification\": classification,\n",
    "        \"draft_answer\": draft_answer,\n",
    "        \"evidence_pack\": json.dumps(evidence_pack, ensure_ascii=False, indent=2) if evidence_pack else \"null\"\n",
    "    })\n",
    "    obj = parse_json_message(msg)\n",
    "\n",
    "    # Required contract\n",
    "    required = {\n",
    "        \"verdict\",\n",
    "        \"major_issues\",\n",
    "        \"minor_issues\",\n",
    "        \"missing_info_questions\",\n",
    "        \"suggested_improvements\"\n",
    "    }\n",
    "\n",
    "    # ✅ Robustness: drop any extra keys the model adds (e.g. \"confidence_level\")\n",
    "    obj = {k: obj.get(k) for k in required}\n",
    "\n",
    "    missing = [k for k, v in obj.items() if v is None]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Critic JSON missing keys: {missing}\")\n",
    "\n",
    "    if obj[\"verdict\"] not in {\"pass\", \"needs_revision\"}:\n",
    "        raise ValueError(f\"Invalid critic verdict: {obj['verdict']}\")\n",
    "\n",
    "    return obj\n",
    "\n",
    "\n",
    "# Re-register CriticAgent with the patched run()\n",
    "CriticAgent = Agent(\n",
    "    name=\"CriticAgent\",\n",
    "    description=\"Quality assurance agent that reviews drafted answers; returns structured feedback.\",\n",
    "    run=critic_agent_run\n",
    ")\n",
    "AGENTS[\"critic\"] = CriticAgent\n",
    "\n",
    "print(\"CriticAgent patched ✅ (extra keys ignored)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "772163df-9ef3-4ff4-83db-efe117cb4412",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "async def run_with_critic(user_text: str) -> Dict[str, Any]:\n",
    "    ctx = InvocationContext(current_message=Message(role=\"user\", text=user_text))\n",
    "\n",
    "    events = []\n",
    "    async for ev in timed_query_router_agent.run(ctx):\n",
    "        events.append(ev)\n",
    "\n",
    "    draft_result = extract_result_from_events(events)\n",
    "\n",
    "    classification = draft_result[\"classification\"]\n",
    "    draft_answer = draft_result[\"response\"]\n",
    "    evidence_pack = draft_result.get(\"evidence_pack\")\n",
    "\n",
    "    critic_feedback = await _run_in_thread(\n",
    "        AGENTS[\"critic\"].run,\n",
    "        user_text,\n",
    "        classification,\n",
    "        draft_answer,\n",
    "        evidence_pack\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"user_prompt\": user_text,\n",
    "        \"classification\": classification,\n",
    "        \"routing_reason\": draft_result[\"routing_reason\"],\n",
    "        \"agent_used\": draft_result[\"agent_used\"],\n",
    "        \"evidence_pack\": evidence_pack,\n",
    "        \"draft_answer\": draft_answer,\n",
    "        \"critic_feedback\": critic_feedback,\n",
    "        \"events\": events,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "72e7b5f5-3b6b-4fb2-a285-5eb835f53351",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "reviser_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "You are the Reviser Agent.\n",
    "\n",
    "Goal: Improve the draft answer by addressing the Critic feedback.\n",
    "Rules:\n",
    "- Do NOT invent facts. If uncertain, say so explicitly.\n",
    "- Keep the answer clear and concise.\n",
    "- If classification is internet_search and evidence is low-confidence, emphasize verification steps.\n",
    "- Address major issues first; incorporate suggested improvements.\n",
    "- Return plain text only.\n",
    "\n",
    "User prompt:\n",
    "{user_prompt}\n",
    "\n",
    "Routing classification:\n",
    "{classification}\n",
    "\n",
    "Evidence pack (may be null):\n",
    "{evidence_pack}\n",
    "\n",
    "Draft answer:\n",
    "{draft_answer}\n",
    "\n",
    "Critic feedback (JSON):\n",
    "{critic_feedback}\n",
    "\n",
    "Write the revised answer:\n",
    "\"\"\")\n",
    "\n",
    "reviser_chain = reviser_prompt | reasoning_llm\n",
    "\n",
    "\n",
    "async def run_with_critic_and_revise(\n",
    "    user_text: str,\n",
    "    *,\n",
    "    max_revision_rounds: int = 1,\n",
    "    re_critic_after_revision: bool = True\n",
    ") -> Dict[str, Any]:\n",
    "    bundle = await run_with_critic(user_text)\n",
    "\n",
    "    classification = bundle[\"classification\"]\n",
    "    evidence_pack = bundle.get(\"evidence_pack\")\n",
    "    revised_answer = bundle[\"draft_answer\"]\n",
    "    critic_feedback = bundle[\"critic_feedback\"]\n",
    "\n",
    "    critic_after = None\n",
    "\n",
    "    for _ in range(max_revision_rounds):\n",
    "        if critic_feedback.get(\"verdict\") == \"pass\":\n",
    "            break\n",
    "\n",
    "        msg = reviser_chain.invoke({\n",
    "            \"user_prompt\": user_text,\n",
    "            \"classification\": classification,\n",
    "            \"evidence_pack\": json.dumps(evidence_pack, ensure_ascii=False, indent=2) if evidence_pack else \"null\",\n",
    "            \"draft_answer\": revised_answer,\n",
    "            \"critic_feedback\": json.dumps(critic_feedback, ensure_ascii=False, indent=2),\n",
    "        })\n",
    "        revised_answer = msg.content\n",
    "\n",
    "        if re_critic_after_revision:\n",
    "            critic_after = await _run_in_thread(\n",
    "                AGENTS[\"critic\"].run,\n",
    "                user_text,\n",
    "                classification,\n",
    "                revised_answer,\n",
    "                evidence_pack\n",
    "            )\n",
    "            critic_feedback = critic_after\n",
    "\n",
    "    return {\n",
    "        **bundle,\n",
    "        \"revised_answer\": revised_answer,\n",
    "        \"critic_after_revision\": critic_after\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2cdac6ce-efa8-4f41-a6aa-936c73f3bba9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'missing_info_questions': ['What is the current CPI data release from the BLS website?', 'What are the recent inflation trends according to news articles or economic reports from reputable sources?'], 'suggested_improvements': [\"The assistant could provide a more direct answer to the user's question, such as 'The current inflation rate in the US is around 2-3%, but this should be confirmed through more recent and reliable sources.'\", 'The assistant could also provide more specific information about the sources used to estimate the inflation rate and the recent inflation trends.'], 'minor_issues': ['The assistant could provide more context about the historical trends and pre-pandemic data used to estimate the inflation rate.', 'The assistant could also provide more specific information about the sources used to estimate the inflation rate.'], 'verdict': 'needs_revision', 'major_issues': [\"The assistant's answer is too vague and doesn't provide a clear conclusion about the current inflation rate in the US.\", \"The assistant fails to provide a direct answer to the user's question, instead focusing on the uncertainty and the need for verification.\"]}\nBased on the evidence pack, the current inflation rate in the US is around 2-3%, but this should be confirmed through more recent and reliable sources.\n\nThe Bureau of Labor Statistics (BLS) is the primary source for US inflation data, and the Consumer Price Index (CPI) is the key metric used to measure inflation. However, the BLS website or direct contact with the BLS is necessary to obtain the most up-to-date information.\n\nRecent inflation trends can be found in news articles or economic reports from reputable sources, such as the Federal Reserve or the Wall Street Journal. These sources can provide more information about the current state of inflation in the US.\n\n**Confidence level:** Low\n\n**Uncertainty:** The current inflation rate in the US is uncertain and should be verified through more recent and reliable sources.\n\n**Verification needed:** Consult the latest CPI data release from the BLS website or contact the BLS directly for the most up-to-date information, and review news articles or economic reports from reputable sources to stay informed about recent inflation trends.\n{'missing_info_questions': ['What is the current CPI data release from the BLS that the assistant is referring to?', 'Are there any specific news articles or economic reports from reputable sources that the assistant recommends for staying informed about recent inflation trends?'], 'suggested_improvements': ['Provide a clear and direct statement of the current inflation rate, if possible, or a more specific estimate based on recent data.', 'Offer a more detailed and actionable plan for users to verify the information, such as providing a link to the BLS website or a specific news article.'], 'minor_issues': ['The answer could benefit from a more concise and direct structure.', \"The use of phrases like 'around 2-3%' could be clarified as a range or an estimate.\"], 'verdict': 'needs_revision', 'major_issues': ['The answer is still uncertain and lacks a specific, up-to-date figure, despite acknowledging the need for verification.', 'The assistant should provide a more direct and clear call to action for users to verify the information.']}\n"
     ]
    }
   ],
   "source": [
    "result = await run_with_critic_and_revise(\"What is the current inflation rate in the US?\")\n",
    "print(result[\"critic_feedback\"])\n",
    "print(result[\"revised_answer\"])\n",
    "print(result[\"critic_after_revision\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2338b674-5c47-45e1-864d-843fdbc69044",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": "HIGH"
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "09_optimization",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}