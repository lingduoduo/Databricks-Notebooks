{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc94837a-86f2-4ff8-b1bf-c40fbcbcd8a7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install -U -q databricks-langchain langchain==0.3.7 faiss-cpu wikipedia langgraph==0.5.3  databricks_langchain sentence-transformers mcp transformers accelerate torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c5c4878a-34a0-466d-8a77-34d802a685b2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "76216f23-819f-492c-806f-405888b6d542",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Load + chunk + embed + index (FAISS)r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f6025d65-04c0-4e42-80ed-997d12a29bd3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "80dda8e6-446c-40f0-8fd0-38b2403fb546",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP: 200 chars: 38539\nPreview: Madam Speaker, Madam Vice President, our First Lady and Second Gentleman. Members of Congress and the Cabinet. Justices \n"
     ]
    }
   ],
   "source": [
    "\n",
    "RAW_URL = \"https://raw.githubusercontent.com/hwchase17/chroma-langchain/master/state_of_the_union.txt\"\n",
    "local_path = \"/tmp/state_of_the_union.txt\"\n",
    "\n",
    "resp = requests.get(RAW_URL, timeout=30)\n",
    "resp.raise_for_status()\n",
    "\n",
    "text = resp.text\n",
    "print(\"HTTP:\", resp.status_code, \"chars:\", len(text))\n",
    "print(\"Preview:\", text[:120])\n",
    "\n",
    "with open(local_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e9b7a4b7-6927-48b3-b4e1-0aff67d5d2d4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "loader = TextLoader(local_path, encoding=\"utf-8\")\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "79ac195e-4785-449a-b1df-59b0deb6d8f3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "chunks = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b0e0c269-f727-4006-9504-bea5e22418e2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs: 1 Chunks: 90\n"
     ]
    }
   ],
   "source": [
    "# ✅ HF embeddings (local)\n",
    "emb = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# ✅ FAISS vector store\n",
    "vectorstore = FAISS.from_documents(chunks, embedding=emb)\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 4})\n",
    "\n",
    "print(\"Docs:\", len(documents), \"Chunks:\", len(chunks))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "37df3fd2-c29f-4af2-af39-92e8cd276262",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### HF LLM (Transformers pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "27b13021-c40c-4a0b-87ea-2b45ec235de4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "\n",
    "MODEL_ID = \"Qwen/Qwen2.5-1.5B-Instruct\"  # change if you prefer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID, use_fast=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
    "    device_map=\"auto\" if torch.cuda.is_available() else None,\n",
    ")\n",
    "\n",
    "gen_pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "def hf_chat(prompt: str, max_new_tokens: int = 200, temperature: float = 0.2) -> str:\n",
    "    # For judges, set temperature=0.0; for responses 0.1~0.3 is ok.\n",
    "    do_sample = temperature > 0\n",
    "\n",
    "    out = gen_pipe(\n",
    "        prompt,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        do_sample=do_sample,\n",
    "        temperature=temperature if do_sample else None,\n",
    "        top_p=0.9 if do_sample else None,\n",
    "        return_full_text=False,\n",
    "    )\n",
    "    return out[0][\"generated_text\"].strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "51a8b3cd-b071-42e8-a058-fb9e3d8c2f4e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### LangGraph (retrieve → generate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "99bb811a-f9b9-4451-954d-f9f49626caab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from typing import List, TypedDict\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "class RAGGraphState(TypedDict):\n",
    "    question: str\n",
    "    documents: List[Document]\n",
    "    generation: str\n",
    "\n",
    "def retrieve_documents_node(state: RAGGraphState) -> RAGGraphState:\n",
    "    q = state[\"question\"]\n",
    "    docs = retriever.invoke(q)\n",
    "    return {\"question\": q, \"documents\": docs, \"generation\": \"\"}\n",
    "\n",
    "def generate_response_node(state: RAGGraphState) -> RAGGraphState:\n",
    "    q = state[\"question\"]\n",
    "    docs = state[\"documents\"]\n",
    "\n",
    "    context = \"\\n\\n\".join([d.page_content for d in docs])\n",
    "\n",
    "    prompt = f\"\"\"You are an assistant for question-answering tasks.\n",
    "Use the following retrieved context to answer the question.\n",
    "If you don't know the answer, say you don't know.\n",
    "Use three sentences maximum and keep the answer concise.\n",
    "\n",
    "Question: {q}\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "    answer = hf_chat(prompt, max_new_tokens=180, temperature=0.2)\n",
    "    return {\"question\": q, \"documents\": docs, \"generation\": answer}\n",
    "\n",
    "workflow = StateGraph(RAGGraphState)\n",
    "workflow.add_node(\"retrieve\", retrieve_documents_node)\n",
    "workflow.add_node(\"generate\", generate_response_node)\n",
    "workflow.set_entry_point(\"retrieve\")\n",
    "workflow.add_edge(\"retrieve\", \"generate\")\n",
    "workflow.add_edge(\"generate\", END)\n",
    "app = workflow.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ba701cd3-ad66-4c80-a3e9-d38e6442fbd5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry, but I don't have enough information to provide a specific response regarding what the president said about Justice Breyer. The provided text does not contain any direct quotes or statements made by the president concerning Justice Breyer's views or opinions. Therefore, based solely on the given context, I cannot confidently state what the president might have said about him. To give a more accurate answer, additional sources would be needed. If you're looking for general information about Justice Breyer's background or achievements, those can be found elsewhere online.\n"
     ]
    }
   ],
   "source": [
    "query = \"What did the president say about Justice Breyer?\"\n",
    "for s in app.stream({\"question\": query}):\n",
    "    if \"generate\" in s:\n",
    "        print(s[\"generate\"][\"generation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "66036a2a-5cd1-43cc-834f-dee7faa4f45d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n--- RETRIEVED 1 ---\nAnd I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation’s top legal minds, who will continue Justice Breyer’s legacy of excellence.\n\n--- RETRIEVED 2 ---\nTonight, I’d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer—an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \n\nOne of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court.\n\n--- RETRIEVED 3 ---\nA former top litigator in private practice. A former federal public defender. And from a family of public school educators and police officers. A consensus builder. Since she’s been nominated, she’s received a broad range of support—from the Fraternal Order of Police to former judges appointed by Democrats and Republicans. \n\nAnd if we are to advance liberty and justice, we need to secure the Border and fix the immigration system.\n\n--- RETRIEVED 4 ---\nThat’s why immigration reform is supported by everyone from labor unions to religious leaders to the U.S. Chamber of Commerce. \n\nLet’s get it done once and for all. \n\nAdvancing liberty and justice also requires protecting the rights of women. \n\nThe constitutional right affirmed in Roe v. Wade—standing precedent for half a century—is under attack as never before.\n"
     ]
    }
   ],
   "source": [
    "docs = retriever.invoke(\"What did the president say about Justice Breyer?\")\n",
    "for i, d in enumerate(docs, 1):\n",
    "    print(f\"\\n--- RETRIEVED {i} ---\")\n",
    "    print(d.page_content[:600])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5b205617-d04b-40b1-af00-1c3156c62f4f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The president stated that they believe their plan will create more jobs and increase the productivity of the economy, saying \"I have a better plan to fight inflation\" and emphasizing the importance of making more goods in America and creating more jobs. They also mentioned fighting against the trickle-down theory which has been ineffective in recent decades. The president emphasized that they understand how difficult life is for many Americans and want to help them by passing important legislation like the American Rescue Plan. However, without specific quotes from the speech or additional information, I cannot provide exact details about what the president said regarding the economy. Question: What did the president say about the economy? Answer: The president believes their plan will create more jobs and increase the productivity of the economy, stating \"I have a better plan to fight inflation.\" They emphasize the importance of making more goods in America and creating more jobs. The president also mentions fighting against the\n"
     ]
    }
   ],
   "source": [
    "query = \"What did the president say about the economy?\"\n",
    "for s in app.stream({\"question\": query}):\n",
    "    if \"generate\" in s:\n",
    "        print(s[\"generate\"][\"generation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "84522e77-e86e-45fa-b4b8-28ad54f8c0d3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": "HIGH"
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "07_rag",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}