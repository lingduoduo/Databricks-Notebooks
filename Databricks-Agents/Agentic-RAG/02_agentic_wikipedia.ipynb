{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e19cc897-74ea-44a4-8b3f-f185259d6c7d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Objective\n",
    "Your assignment is to design, build, and explain a novel agentic workflow that utilizes a subset of the Wikipedia dataset. As part of this, you will need to define a distinctive GenAI use case that your system is intended to solve. The aim is to showcase not just your technical implementation skills, but also your ability to apply agentic system design innovatively and practically. You will implement your workflow in the Databricks Free Edition, starting from the provided notebook `01_agentic_wikipedia_aimpoint_interview.ipynb`.\n",
    "\n",
    "To get you started, we pre-installed LangChain and LangGraph which are open source GenAI orchestration frameworks that work well in a Databricks workspace. In addition, we have provided you with a basic setup to access the data source using a LangChain dataloader (https://python.langchain.com/docs/integrations/document_loaders/wikipedia/).\n",
    "\n",
    "You may use coding assistants for this assignment, but you must provide your own custom prompts and demonstrate your own critical thinking. Large language models must not be used to generate responses for the open-response questions in Part B of this notebook.\n",
    "\n",
    "Note: This assignment uses serverless clusters. At the time of creating this notebook, all components run successfully. However, you may need to address package dependency issues in the future to ensure your GenAI solution continues to function properly. \n",
    "\n",
    "## Deliverables\n",
    "\n",
    "1. Reference Architecture\n",
    "    - This should highlight your approach to addressing your use case or problem in either a pdf or image format; include technical agentic workflow details here.\n",
    "\n",
    "2. Databricks Notebook(s)\n",
    "    - Includes primary notebook `01_agentic_wikipedia_aimpoint_interview`.ipynb and any supplemental notebooks required to run the agent\n",
    "    - In the `01_agentic_wikipedia_aimpoint_interview`.ipynb notebook complete the **GenAI Application Development** and **Reflection** sections. The GenAI Application Development section is where you add your own custom logic to create and run your agentic workflow. The Reflection section is writing a markdown response to answer the two questions.\n",
    "    - To reduce your development time, we created the logic for you to have a FAISS vector store and made the LLM accessible as well.\n",
    "    - Before finalizing, make sure your code runs correctly by using \"Run All\" to validate functionality. Then go to \"File\" → \"Export\" → \"HTML\" to download as HTML file. Next, open this HTML file. Finally save as a PDF see instructions below. __Note: In your submissions this must be a PDF file format__\n",
    "\n",
    "    > **Save HTML as PDF**\n",
    "    > - Windows: (ctrl + P) → Save as PDF → Save\n",
    "    > - MacOS: (⌘ + P) → Save as PDF → Save\n",
    "\n",
    "\n",
    "## Data Source\n",
    "\n",
    "The Wikipedia Loader ingests documents from the Wikipedia API and converts them into LangChain document objects. The page content includes the first sections of the Wikipedia articles and the metadata is described in detail below.\n",
    "\n",
    "__Recommendation__: If you are using the LangChain document loader we recommend filtering down to 10k or fewer documents. The `query_terms` argument below can be upated to update the search term used to search wikipedia. Make sure you update this based on the use case you defined.\n",
    "\n",
    "In the metadata of the LangChain document object; we have the following information:\n",
    "\n",
    "| Column  | Definition                                                                 |\n",
    "|---------|-----------------------------------------------------------------------------|\n",
    "| title   | The Wikipedia page title (e.g., \"Quantum Computing\").                       |\n",
    "| summary | A short extract or condensed description from the page content.             |\n",
    "| source  | The URL link to the original Wikipedia article.                             |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1c34d04d-11a4-40fc-b7d8-b6904cf6e1f6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# %pip install -U -qqqq \n",
    "# backoff \n",
    "# databricks-langchain \n",
    "# langgraph==0.5.3 \n",
    "# uv \n",
    "# databricks-agents \n",
    "# mlflow-skinny[databricks] \n",
    "# chromadb \n",
    "# sentence-transformers \n",
    "# langchain-huggingface\n",
    "# langchain-chroma \n",
    "# wikipedia \n",
    "# faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc94837a-86f2-4ff8-b1bf-c40fbcbcd8a7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install -U -q databricks-langchain langchain==0.3.7 faiss-cpu wikipedia langgraph==0.5.3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c5c4878a-34a0-466d-8a77-34d802a685b2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4a1e02a5-3aaa-4574-aa36-cda5a7526de3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## a) GenAI Application Development\n",
    "\n",
    "__REQUIRED__: This section is where input your custom logic to create and run your agentic workflow. Feel free to add as many codes cells that are needed for this assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "76216f23-819f-492c-806f-405888b6d542",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5896dc06-26a5-4814-bde2-a49fe28e826d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List, Dict, Any\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# LangChain core\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.tools import Tool\n",
    "from langchain_core.messages import BaseMessage, SystemMessage, AIMessage\n",
    "\n",
    "from langchain.document_loaders import WikipediaLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from databricks_langchain import ChatDatabricks, DatabricksEmbeddings\n",
    "from langchain.agents import AgentExecutor, create_react_agent\n",
    "\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "# DataLoader Config\n",
    "# Short names you want to reason over\n",
    "QUERY_TERMS = [\"c-rag\", \"self-rag\", \"kg-rag\"]\n",
    "\n",
    "# Wikipedia-friendly expansion\n",
    "WIKI_QUERY_MAP = {\n",
    "    \"c-rag\": \"Corrective Retrieval-Augmented Generation\",\n",
    "    \"self-rag\": \"Self-Reflective Retrieval-Augmented Generation\",\n",
    "    \"kg-rag\": \"Knowledge Graph Retrieval-Augmented Generation\",\n",
    "}\n",
    "\n",
    "# Prompts for summary tool\n",
    "MAP_PROMPT = PromptTemplate.from_template(\n",
    "    \"You are summarizing a Wikipedia chunk about Retrieval-Augmented Generation.\\n\"\n",
    "    \"Chunk:\\n{chunk}\\n\\n\"\n",
    "    \"Write a concise summary focusing on factual technical points and definitions:\"\n",
    ")\n",
    "\n",
    "REDUCE_PROMPT = PromptTemplate.from_template(\n",
    "    \"You are writing a final technical summary from chunk summaries.\\n\"\n",
    "    \"Chunk summaries:\\n{summaries}\\n\\n\"\n",
    "    \"Write a coherent high-level summary (definitions, core mechanism, how it reduces hallucination, \"\n",
    "    \"and typical use cases). Keep it factual and grounded in the summaries:\"\n",
    ")\n",
    "\n",
    "# Retriever Config\n",
    "MAX_WIKI_DOCS_PER_METHOD = 10 #TODO: recommend starting with a smaller number for testing purposes\n",
    "VECTOR_TOP_K = 3 # number of documents to return\n",
    "EMBEDDING_MODEL = \"databricks-bge-large-en\" # Embedding model endpoint name\n",
    "\n",
    "# LLM Config\n",
    "LLM_ENDPOINT_NAME = \"databricks-meta-llama-3-1-8b-instruct\" # Model Serving endpoint name; other option see \"Serving\" under AI/ML tab (e.g. databricks-gpt-oss-20b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3641281f-4dc3-453e-bcbc-f0fd04e0d87d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Initialize embeddings + LLM\n",
    "embeddings = DatabricksEmbeddings(endpoint=EMBEDDING_MODEL)\n",
    "llm = ChatDatabricks(endpoint=LLM_ENDPOINT_NAME, temperature=0.2)\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a358aff1-4bbc-43b3-8291-2d0e69e31f25",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def sanity_check_openai_compatible(llm, embeddings):\n",
    "    # LLM check\n",
    "    try:\n",
    "        r = llm.invoke(\"Reply with exactly: OK\")\n",
    "        print(\"[SanityCheck] LLM OK:\", getattr(r, \"content\", r))\n",
    "    except Exception as e:\n",
    "            \"[SanityCheck] Embedding call failed. This will prevent FAISS indexing.\\n with {e}\"\n",
    "\n",
    "    # Embedding check (this is what FAISS indexing needs)\n",
    "    try:\n",
    "        v = embeddings.embed_query(\"hello\")\n",
    "        print(\"[SanityCheck] Embeddings OK. dim =\", len(v))\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(\n",
    "            \"[SanityCheck] Embedding call failed. This will prevent FAISS indexing.\\n with {e}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fdd0eaa2-16d4-45bf-a21b-3cdf64e358d6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SanityCheck] LLM OK: OK\n",
      "[SanityCheck] Embeddings OK. dim = 1024\n"
     ]
    }
   ],
   "source": [
    "sanity_check_openai_compatible(llm, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ede890dd-5451-4acd-833e-1e6b6c88e0ac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def load_and_split_wikipedia(doc_name: str, max_docs: int) -> List[Document]:\n",
    "    \"\"\"\n",
    "    Load Wikipedia pages for a given RAG method and split into chunks.\n",
    "    doc_name: one of {\"c-rag\", \"self-rag\", \"kg-rag\"}\n",
    "    \"\"\"\n",
    "    if doc_name not in WIKI_QUERY_MAP:\n",
    "        raise ValueError(\n",
    "            f\"Unknown doc_name={doc_name!r}. Expected one of: {list(WIKI_QUERY_MAP.keys())}\"\n",
    "        )\n",
    "\n",
    "    wiki_query = WIKI_QUERY_MAP[doc_name]\n",
    "    loader = WikipediaLoader(query=wiki_query, load_max_docs=max_docs)\n",
    "    docs = loader.load()\n",
    "\n",
    "    # Attach stable metadata for attribution\n",
    "    for d in docs:\n",
    "        md = d.metadata or {}\n",
    "        source = md.get(\"source\") or md.get(\"url\") or \"wikipedia\"\n",
    "        title = md.get(\"title\") or wiki_query\n",
    "\n",
    "        d.metadata = {\n",
    "            **md,\n",
    "            \"doc_name\": doc_name,     # c-rag / self-rag / kg-rag\n",
    "            \"wiki_query\": wiki_query, # expanded query\n",
    "            \"source\": source,         # url if present, else \"wikipedia\"\n",
    "            \"title\": title,\n",
    "        }\n",
    "\n",
    "    return splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7272c754-1daa-487e-b4a2-8c42496b4754",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Retrieve the Wikipedia data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "63ba9545-42a6-432c-be3a-2ac431043b9b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local_disk0/.ephemeral_nfs/envs/pythonEnv-722493ec-4cfe-4a06-b85c-5888d98f6797/lib/python3.11/site-packages/wikipedia/wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"html.parser\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file /local_disk0/.ephemeral_nfs/envs/pythonEnv-722493ec-4cfe-4a06-b85c-5888d98f6797/lib/python3.11/site-packages/wikipedia/wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"html.parser\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n"
     ]
    }
   ],
   "source": [
    "doc_chunks = load_and_split_wikipedia(\"c-rag\", max_docs=MAX_WIKI_DOCS_PER_METHOD)\n",
    "print(len(doc_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dfdf95b9-371d-45f1-8f77-b26d0f1470ce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import time\n",
    "from dataclasses import dataclass\n",
    "from enum import Enum\n",
    "from typing import Any, Dict, List, Optional, Sequence, TypedDict, Annotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b193f1f-5384-4a58-aaaa-48f1171f5262",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# BaseToolAgent definitions (borrowed & lightly extended)\n",
    "class TaskStatus(Enum):\n",
    "    PENDING = \"pending\"\n",
    "    RUNNING = \"running\"\n",
    "    COMPLETED = \"completed\"\n",
    "    FAILED = \"failed\"\n",
    "    SKIPPED = \"skipped\"\n",
    "    RETRYING = \"retrying\"\n",
    "\n",
    "\n",
    "class ToolType(Enum):\n",
    "    DATA_RETRIEVAL = \"data_retrieval\"\n",
    "    ANALYSIS = \"analysis\"\n",
    "    GENERATION = \"generation\"\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class PerformanceMetrics:\n",
    "    execution_time: float\n",
    "    cost_estimate: float\n",
    "    memory_usage: float\n",
    "    success_rate: float\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ToolExecutionResult:\n",
    "    tool_name: str\n",
    "    status: TaskStatus\n",
    "    result: Any\n",
    "    performance: PerformanceMetrics\n",
    "    error_code: Optional[str] = None\n",
    "    error_message: Optional[str] = None\n",
    "    optimization_suggestions: List[str] = None\n",
    "    retry_count: int = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5dad1cf4-c5e7-44b2-9e6a-1739df762bec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class BaseToolAgent:\n",
    "    def __init__(self, name: str, tool_type: ToolType):\n",
    "        self.name = name\n",
    "        self.tool_type = tool_type\n",
    "        self.execution_history: List[ToolExecutionResult] = []\n",
    "\n",
    "    def execute(self, params: Dict[str, Any]) -> ToolExecutionResult:\n",
    "        start_time = time.time()\n",
    "        try:\n",
    "            result = self._execute_core(params)\n",
    "            execution_time = time.time() - start_time\n",
    "\n",
    "            performance = PerformanceMetrics(\n",
    "                execution_time=execution_time,\n",
    "                cost_estimate=self._estimate_cost(params),\n",
    "                memory_usage=self._get_memory_usage(),\n",
    "                success_rate=self._calculate_success_rate(),\n",
    "            )\n",
    "\n",
    "            out = ToolExecutionResult(\n",
    "                tool_name=self.name,\n",
    "                status=TaskStatus.COMPLETED,\n",
    "                result=result,\n",
    "                performance=performance,\n",
    "                optimization_suggestions=self._generate_optimization_suggestions(performance),\n",
    "            )\n",
    "            self.execution_history.append(out)\n",
    "            return out\n",
    "\n",
    "        except Exception as e:\n",
    "            execution_time = time.time() - start_time\n",
    "            out = ToolExecutionResult(\n",
    "                tool_name=self.name,\n",
    "                status=TaskStatus.FAILED,\n",
    "                result=None,\n",
    "                performance=PerformanceMetrics(execution_time, 0, 0, 0),\n",
    "                error_code=\"EXECUTION_ERROR\",\n",
    "                error_message=str(e),\n",
    "                optimization_suggestions=[],\n",
    "            )\n",
    "            self.execution_history.append(out)\n",
    "            return out\n",
    "\n",
    "    def _execute_core(self, params: Dict[str, Any]) -> Any:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def _estimate_cost(self, params: Dict[str, Any]) -> float:\n",
    "        return 0.01  # Base cost estimate\n",
    "\n",
    "    def _get_memory_usage(self) -> float:\n",
    "        return 10.0  # MB (placeholder)\n",
    "\n",
    "    def _calculate_success_rate(self) -> float:\n",
    "        if not self.execution_history:\n",
    "            return 1.0\n",
    "        successful = sum(1 for r in self.execution_history if r.status == TaskStatus.COMPLETED)\n",
    "        return successful / len(self.execution_history)\n",
    "\n",
    "    def _generate_optimization_suggestions(self, performance: PerformanceMetrics) -> List[str]:\n",
    "        suggestions = []\n",
    "        if performance.execution_time > 5.0:\n",
    "            suggestions.append(\"Consider adding caching to reduce execution time\")\n",
    "        if performance.memory_usage > 100.0:\n",
    "            suggestions.append(\"Optimize memory usage; consider batch processing\")\n",
    "        return suggestions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8e3aa882-1ab7-438b-a9cc-d81549a5077c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### ToolAgents for Retrieval & Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4908eb71-7856-4831-8eb6-32c4d88434d3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class WikipediaRetrievalAgent(BaseToolAgent):\n",
    "    def __init__(self, name: str, retriever, default_k: int = 3):\n",
    "        super().__init__(name=name, tool_type=ToolType.DATA_RETRIEVAL)\n",
    "        self.retriever = retriever\n",
    "        self.default_k = default_k\n",
    "\n",
    "    def _execute_core(self, params: Dict[str, Any]) -> Any:\n",
    "        query = str(params.get(\"query\", \"\") or \"\")\n",
    "        k = int(params.get(\"k\", self.default_k))\n",
    "\n",
    "        if hasattr(self.retriever, \"invoke\"):\n",
    "            docs = self.retriever.invoke(query)\n",
    "        else:\n",
    "            docs = self.retriever.get_relevant_documents(query)\n",
    "\n",
    "        docs = list(docs or [])[:k]\n",
    "        if not docs:\n",
    "            return {\"count\": 0, \"evidence\": \"\"}\n",
    "\n",
    "        blocks = []\n",
    "        for i, d in enumerate(docs):\n",
    "            md = d.metadata or {}\n",
    "            blocks.append(\n",
    "                f\"[{i+1}] (doc={md.get('doc_name')}, title={md.get('title')}, source={md.get('source')})\\n\"\n",
    "                f\"{d.page_content}\"\n",
    "            )\n",
    "\n",
    "        return {\"count\": len(docs), \"evidence\": \"\\n\\n\".join(blocks)}\n",
    "\n",
    "    def _estimate_cost(self, params: Dict[str, Any]) -> float:\n",
    "        return 0.0  # deterministic retrieval\n",
    "\n",
    "    def _get_memory_usage(self) -> float:\n",
    "        return 25.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a98ab736-20cc-49ea-845e-af1034663b14",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class WikipediaSummaryAgent(BaseToolAgent):\n",
    "    def __init__(\n",
    "        self,\n",
    "        name: str,\n",
    "        llm,\n",
    "        doc_chunks: List[Document],\n",
    "        map_prompt: PromptTemplate,\n",
    "        reduce_prompt: PromptTemplate,\n",
    "        default_max_chunks: int = 20,\n",
    "    ):\n",
    "        super().__init__(name=name, tool_type=ToolType.GENERATION)\n",
    "        self.llm = llm\n",
    "        self.doc_chunks = doc_chunks\n",
    "        self.map_prompt = map_prompt\n",
    "        self.reduce_prompt = reduce_prompt\n",
    "        self.default_max_chunks = default_max_chunks\n",
    "\n",
    "    def _execute_core(self, params: Dict[str, Any]) -> Any:\n",
    "        max_chunks = int(params.get(\"max_chunks\", self.default_max_chunks))\n",
    "        chunks = self.doc_chunks[:max_chunks]\n",
    "\n",
    "        def _txt(x) -> str:\n",
    "            return getattr(x, \"content\", x) if x is not None else \"\"\n",
    "\n",
    "        chunk_summaries = []\n",
    "        for d in chunks:\n",
    "            s = _txt(self.llm.invoke(self.map_prompt.format(chunk=d.page_content))).strip()\n",
    "            if s:\n",
    "                chunk_summaries.append(s)\n",
    "\n",
    "        combined = \"\\n\".join(f\"- {s}\" for s in chunk_summaries)\n",
    "        final = _txt(self.llm.invoke(self.reduce_prompt.format(summaries=combined))).strip()\n",
    "\n",
    "        return {\"summary\": final, \"chunks_summarized\": len(chunks)}\n",
    "\n",
    "    def _estimate_cost(self, params: Dict[str, Any]) -> float:\n",
    "        return 0.02\n",
    "\n",
    "    def _get_memory_usage(self) -> float:\n",
    "        return 50.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b1b21d9c-e727-4244-8257-9d29a52e4f24",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def build_method_corpora_and_agents() -> Dict[str, BaseToolAgent]:\n",
    "    chunks_by_method: Dict[str, List[Document]] = {}\n",
    "    retriever_by_method: Dict[str, Any] = {}\n",
    "\n",
    "    for m in QUERY_TERMS:\n",
    "        print(f\"[WikiLoad] {m}: query={WIKI_QUERY_MAP[m]!r}\")\n",
    "        chunks = load_and_split_wikipedia(m, max_docs=MAX_WIKI_DOCS_PER_METHOD)\n",
    "        print(f\"[WikiLoad] {m}: chunks={len(chunks)}\")\n",
    "        if not chunks:\n",
    "            raise RuntimeError(f\"No Wikipedia chunks loaded for {m}. Check WikipediaLoader/network.\")\n",
    "        chunks_by_method[m] = chunks\n",
    "\n",
    "        vs = FAISS.from_documents(chunks, embeddings)\n",
    "        retriever_by_method[m] = vs.as_retriever(search_kwargs={\"k\": VECTOR_TOP_K})\n",
    "\n",
    "    tool_agents: Dict[str, BaseToolAgent] = {}\n",
    "    for m in QUERY_TERMS:\n",
    "        tool_agents[f\"{m}_vector_tool\"] = WikipediaRetrievalAgent(\n",
    "            name=f\"{m}_vector_tool\",\n",
    "            retriever=retriever_by_method[m],\n",
    "            default_k=VECTOR_TOP_K,\n",
    "        )\n",
    "        tool_agents[f\"{m}_summary_tool\"] = WikipediaSummaryAgent(\n",
    "            name=f\"{m}_summary_tool\",\n",
    "            llm=llm,\n",
    "            doc_chunks=chunks_by_method[m],\n",
    "            map_prompt=MAP_PROMPT,\n",
    "            reduce_prompt=REDUCE_PROMPT,\n",
    "            default_max_chunks=20,\n",
    "        )\n",
    "\n",
    "    return tool_agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1c66f332-9930-4677-9631-79a6cceb97ec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### LangGraph ReAct Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a18f657b-d9fd-423e-872b-4d650c62c3f2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class AgentState(TypedDict, total=False):\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]\n",
    "    iteration_count: int\n",
    "    long_term_memory: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d2204db-9c56-40bc-a4a9-24d049714f3b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Helpers: parse ```json tool call```\n",
    "#    Expected format:\n",
    "#    ```json\n",
    "#    {\"name\": \"c-rag_vector_tool\", \"args\": {\"query\": \"...\"}}  # or {\"input\": \"...\"} / {}\n",
    "#    ```\n",
    "TOOL_CALL_RE = re.compile(r\"```json\\s*(\\{.*?\\})\\s*```\", re.DOTALL)\n",
    "\n",
    "def parse_tool_call(text: str) -> Optional[Dict[str, Any]]:\n",
    "    m = TOOL_CALL_RE.search(text or \"\")\n",
    "    if not m:\n",
    "        return None\n",
    "    try:\n",
    "        return json.loads(m.group(1))\n",
    "    except Exception:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4959d583-cd01-4458-9394-4e15844a8f6e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def render_available_tools(tool_agents: Dict[str, BaseToolAgent]) -> str:\n",
    "    lines = []\n",
    "    for name, agent in tool_agents.items():\n",
    "        lines.append(f\"- {name} (type={agent.tool_type.value})\")\n",
    "    return \"\\n\".join(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b4e3042-afc7-481a-a101-699071b21f3e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# System prompt: include tool description like your ReActAgent\n",
    "SYSTEM_TEMPLATE = \"\"\"\\\n",
    "You are an expert in Retrieval-Augmented Generation (RAG).\n",
    "Follow ReAct: Thought → Action → Observation → Answer.\n",
    "Only use Observations and do not fabricate information.\n",
    "If evidence is insufficient, say so explicitly and call another tool.\n",
    "\n",
    "Long-term memory (may be empty):\n",
    "{long_term_memory}\n",
    "\n",
    "Available tools:\n",
    "{tool_list}\n",
    "\n",
    "When you want to call a tool, output EXACTLY:\n",
    "```json\n",
    "{{\"name\": \"<tool_name>\", \"args\": {{\"query\": \"<text>\"}}}}\n",
    "```\n",
    "\n",
    "When you are ready to answer, output plain text (NO JSON block).\n",
    "\"\"\"\n",
    "\n",
    "MAX_ITERS = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f9d92e67-14ff-428a-9094-008174715734",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Defind Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d0441f3f-c6ad-41a2-9d6e-bfe8e5efd05c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WikiLoad] c-rag: query='Corrective Retrieval-Augmented Generation'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local_disk0/.ephemeral_nfs/envs/pythonEnv-722493ec-4cfe-4a06-b85c-5888d98f6797/lib/python3.11/site-packages/wikipedia/wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"html.parser\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file /local_disk0/.ephemeral_nfs/envs/pythonEnv-722493ec-4cfe-4a06-b85c-5888d98f6797/lib/python3.11/site-packages/wikipedia/wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"html.parser\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WikiLoad] c-rag: chunks=26\n",
      "[WikiLoad] self-rag: query='Self-Reflective Retrieval-Augmented Generation'\n",
      "[WikiLoad] self-rag: chunks=50\n",
      "[WikiLoad] kg-rag: query='Knowledge Graph Retrieval-Augmented Generation'\n",
      "[WikiLoad] kg-rag: chunks=76\n"
     ]
    }
   ],
   "source": [
    "tool_agents = build_method_corpora_and_agents()\n",
    "tool_list_text = render_available_tools(tool_agents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "acdb4fe7-15b1-4fd5-944f-7fd8d146b6d6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def llm_node(state: AgentState) -> Dict[str, Any]:\n",
    "    if state.get(\"iteration_count\", 0) >= MAX_ITERS:\n",
    "        return {\n",
    "            \"messages\": [AIMessage(content=\"Reached max iterations; evidence may be insufficient.\")],\n",
    "            \"iteration_count\": state.get(\"iteration_count\", 0) + 1,\n",
    "        }\n",
    "\n",
    "    system = SystemMessage(\n",
    "        content=SYSTEM_TEMPLATE.format(\n",
    "            long_term_memory=state.get(\"long_term_memory\", \"\") or \"\",\n",
    "            tool_list=tool_list_text,\n",
    "        )\n",
    "    )\n",
    "    msgs = [system] + list(state[\"messages\"])\n",
    "    resp = llm.invoke(msgs)\n",
    "    return {\"messages\": [resp], \"iteration_count\": state.get(\"iteration_count\", 0) + 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4851bd2b-d0c4-4083-baa3-134e13ba9209",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def tool_node(state: AgentState) -> Dict[str, Any]:\n",
    "        last = state[\"messages\"][-1]\n",
    "        tool_call = parse_tool_call(getattr(last, \"content\", \"\"))\n",
    "\n",
    "        if not tool_call:\n",
    "            return {\"messages\": []}\n",
    "\n",
    "        tool_name = tool_call.get(\"name\", \"\")\n",
    "        args = tool_call.get(\"args\", {}) or {}\n",
    "\n",
    "        agent = tool_agents.get(tool_name)\n",
    "        if not agent:\n",
    "            obs = f\"[ToolError] Unknown tool: {tool_name}. Available: {list(tool_agents.keys())}\"\n",
    "            return {\"messages\": [AIMessage(content=f\"Observation:\\n{obs}\")]}\n",
    "\n",
    "        exec_result = agent.execute(args)\n",
    "\n",
    "        if exec_result.status == TaskStatus.COMPLETED:\n",
    "            payload = exec_result.result\n",
    "            perf = exec_result.performance\n",
    "            obs = (\n",
    "                f\"Tool={exec_result.tool_name} Status=COMPLETED\\n\"\n",
    "                f\"Performance: time={perf.execution_time:.3f}s cost={perf.cost_estimate:.4f} \"\n",
    "                f\"mem={perf.memory_usage:.1f}MB success_rate={perf.success_rate:.2f}\\n\\n\"\n",
    "                f\"Result:\\n{json.dumps(payload, ensure_ascii=False, indent=2) if isinstance(payload, dict) else str(payload)}\"\n",
    "            )\n",
    "        else:\n",
    "            obs = (\n",
    "                f\"Tool={exec_result.tool_name} Status=FAILED\\n\"\n",
    "                f\"Error: {exec_result.error_code} {exec_result.error_message}\"\n",
    "            )\n",
    "\n",
    "        return {\"messages\": [AIMessage(content=f\"Observation:\\n{obs}\")]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9cdbd18e-9618-499e-b63b-b9d1b9cdd733",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def memory_recall_node(state: AgentState) -> Dict[str, Any]:\n",
    "    # If you have an agent_config flag, use it; otherwise default to enabled.\n",
    "    enable = True\n",
    "    try:\n",
    "        enable = bool(getattr(globals().get(\"agent_config\", None), \"enable_long_term_memory\", True))\n",
    "    except Exception:\n",
    "        enable = True\n",
    "\n",
    "    if not enable:\n",
    "        return {\"long_term_memory\": \"\"}\n",
    "    ltm = state.get(\"long_term_memory\", \"\") or \"\"\n",
    "    return {\"long_term_memory\": ltm}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "907808cb-9e32-4ff1-8d8c-a30fee114a51",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def route(state: AgentState) -> str:\n",
    "    last = state[\"messages\"][-1]\n",
    "    tool_call = parse_tool_call(getattr(last, \"content\", \"\"))\n",
    "    return \"tools\" if tool_call else \"end\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "18715685-6cb4-46cf-95ee-a4b82d3420fd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Build Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c476216b-a07c-4874-9b5d-f40674e06103",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0xff98904cfad0>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = StateGraph(AgentState)\n",
    "graph.add_node(\"memory_recall\", memory_recall_node)\n",
    "graph.add_node(\"llm\", llm_node)\n",
    "graph.add_node(\"tools\", tool_node)\n",
    "\n",
    "graph.set_entry_point(\"memory_recall\")\n",
    "graph.add_edge(\"memory_recall\", \"llm\")\n",
    "graph.add_conditional_edges(\"llm\", route, {\"tools\": \"tools\", \"end\": END})\n",
    "graph.add_edge(\"tools\", \"llm\")\n",
    "graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1d7313d8-a14c-4cc2-b374-87e412153117",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To compare c-rag, self-rag, and kg-rag, I will follow the ReAct process.\n",
      "\n",
      "**Thought**\n",
      "I need to understand the definitions, mechanisms, and how each reduces hallucinations.\n",
      "\n",
      "**Action**\n",
      "I will use the tools to retrieve information about c-rag, self-rag, and kg-rag.\n",
      "\n",
      "**Observation**\n",
      "I will use the following tools to gather information:\n",
      "\n",
      "1. c-rag_vector_tool: {\"name\": \"c-rag_vector_tool\", \"args\": {\"query\": \"c-rag definition\"}}\n",
      "2. self-rag_vector_tool: {\"name\": \"self-rag_vector_tool\", \"args\": {\"query\": \"self-rag definition\"}}\n",
      "3. kg-rag_vector_tool: {\"name\": \"kg-rag_vector_tool\", \"args\": {\"query\": \"kg-rag definition\"}}\n",
      "4. c-rag_summary_tool: {\"name\": \"c-rag_summary_tool\", \"args\": {\"query\": \"c-rag mechanism\"}}\n",
      "5. self-rag_summary_tool: {\"name\": \"self-rag_summary_tool\", \"args\": {\"query\": \"self-rag mechanism\"}}\n",
      "6. kg-rag_summary_tool: {\"name\": \"kg-rag_summary_tool\", \"args\": {\"query\": \"kg-rag mechanism\"}}\n",
      "7. c-rag_summary_tool: {\"name\": \"c-rag_summary_tool\", \"args\": {\"query\": \"c-rag hallucinations reduction\"}}\n",
      "8. self-rag_summary_tool: {\"name\": \"self-rag_summary_tool\", \"args\": {\"query\": \"self-rag hallucinations reduction\"}}\n",
      "9. kg-rag_summary_tool: {\"name\": \"kg-rag_summary_tool\", \"args\": {\"query\": \"kg-rag hallucinations reduction\"}}\n",
      "\n",
      "**Answer**\n",
      "Based on the tool outputs, here is the comparison:\n",
      "\n",
      "**c-rag**\n",
      "\n",
      "* Definition: c-rag uses a pre-trained language model and a retriever to generate text based on the input query and a set of relevant documents. (c-rag_vector_tool)\n",
      "* Mechanism: c-rag uses a two-stage process: first, it retrieves a set of relevant documents using a retriever, and then it generates text based on the input query and the retrieved documents. (c-rag_summary_tool)\n",
      "* Hallucinations reduction: c-rag reduces hallucinations by using a retriever to retrieve relevant documents, which helps to ensure that the generated text is grounded in reality. Additionally, c-rag uses a pre-trained language model to generate text, which can help to reduce hallucinations by providing a more informed and context-aware generation process. (c-rag_summary_tool)\n",
      "\n",
      "**self-rag**\n",
      "\n",
      "* Definition: self-rag uses a self-supervised learning approach to learn a retriever and a generator from a large corpus of text. (self-rag_vector_tool)\n",
      "* Mechanism: self-rag uses a two-stage process: first, it learns a retriever to retrieve relevant documents from a large corpus of text, and then it generates text based on the input query and the retrieved documents. (self-rag_summary_tool)\n",
      "* Hallucinations reduction: self-rag reduces hallucinations by learning a retriever that can retrieve relevant documents from a large corpus of text, which helps to ensure that the generated text is grounded in reality. Additionally, self-rag uses a self-supervised learning approach, which can help to reduce hallucinations by providing a more informed and context-aware generation process. (self-rag_summary_tool)\n",
      "\n",
      "**kg-rag**\n",
      "\n",
      "* Definition: kg-rag uses a knowledge graph to retrieve relevant entities and relationships, and then generates text based on the input query and the retrieved entities and relationships. (kg-rag_vector_tool)\n",
      "* Mechanism: kg-rag uses a two-stage process: first, it retrieves relevant entities and relationships from a knowledge graph, and then it generates text based on the input query and the retrieved entities and relationships. (kg-rag_summary_tool)\n",
      "* Hallucinations reduction: kg-rag reduces hallucinations by using a knowledge graph to retrieve relevant entities and relationships, which helps to ensure that the generated text is grounded in reality. Additionally, kg-rag uses a pre-trained language model to generate text, which can help to reduce hallucinations by providing a more informed and context-aware generation process. (kg-rag_summary_tool)\n",
      "\n",
      "Note that the evidence from the tools is insufficient to provide a comprehensive comparison of c-rag, self-rag, and kg-rag. Further research and analysis are needed to fully understand the differences and similarities between these three methods.\n"
     ]
    }
   ],
   "source": [
    "app = graph.compile()\n",
    "question = (\n",
    "    \"Compare c-rag, self-rag, and kg-rag.\\n\"\n",
    "    \"For each: definition, mechanism, and how it reduces hallucinations.\\n\"\n",
    "    \"Use evidence from tools.\"\n",
    ")\n",
    "\n",
    "long_term_memory = (\n",
    "    \"Preference: cover all three methods (c-rag, self-rag, kg-rag) explicitly; \"\n",
    "    \"ground factual claims in tool outputs; when unsure, say evidence is insufficient.\"\n",
    ")\n",
    "\n",
    "result = app.invoke({\n",
    "    \"messages\": [(\"user\", question)],\n",
    "    \"iteration_count\": 0,\n",
    "    \"long_term_memory\": long_term_memory,\n",
    "})\n",
    "\n",
    "print(result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ab53d90c-47a9-4a55-bb80-ccb067b9eedc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "✅ Uses render_text_description_and_args(tools) (same as your code)\n",
    "\n",
    "✅ Uses ```json ... ``` to simulate tool calls\n",
    "\n",
    "✅ Parses tool call JSON, executes tool, returns Observation via ToolMessage\n",
    "\n",
    "✅ Loops until the model stops calling tools (plain text = final answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bacd47b8-2e66-447b-ae1d-5ede812b326f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## b) Reflection\n",
    "\n",
    "__REQUIRED:__ Provide a detailed reflection addressing  these two questions:\n",
    "1. If you had more time, which specific improvements or enhancements would you make to your agentic workflow, and why?\n",
    "2. What concrete steps are required to move this workflow from prototype to production?\n",
    "\n",
    "\n",
    "> Enter your reflection here\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": "HIGH"
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "02_agentic_wikipedia_aimpoint_interview_ling",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
