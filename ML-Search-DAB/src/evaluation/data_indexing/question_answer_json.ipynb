{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "secret_scope = dbutils.widgets.get(\"secret_scope\")\n",
    "\n",
    "if secret_scope.split(\"-\")[0] == \"prod\":\n",
    "    dbutils.notebook.exit(\"Skip run in prod environment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_catalog = dbutils.widgets.get(\"ml_catalog\")\n",
    "ml_search_db = dbutils.widgets.get(\"ml_search_db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Question and Answer Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "\n",
    "boto3_session = boto3.Session(\n",
    "    botocore_session=dbutils.credentials.getServiceCredentialsProvider(\n",
    "        'service-cred-nas-lifion_ml-sdq-dit'\n",
    "    )\n",
    ")\n",
    "\n",
    "bucket_name = \"ml-models-bucket-appbuild-02\"\n",
    "file_path = \"evaluation_framework/raw-qna-data.json\"\n",
    "\n",
    "s3_client = boto3_session.client('s3') \n",
    "response = s3_client.get_object(Bucket=bucket_name, Key=file_path)\n",
    "data = json.load(response['Body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['id', 'description_t', 'metadata_s', 'type_t', 'clientId_ss']\n",
    "df = spark.createDataFrame(data)[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupBy(['type_t']).count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import concat_ws\n",
    "\n",
    "df_qna = df.withColumn(\n",
    "    \"combined\", \n",
    "    concat_ws(\" | \", df[\"id\"], df['metadata_s'])\n",
    ").filter(df.type_t == \"qna\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_qna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdf = df_qna.sample(fraction=0.01).toPandas()\n",
    "pdf =  df_qna.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "current_dir = Path.cwd()\n",
    "parent_dir = current_dir.parent.parent.parent\n",
    "sys.path.append(str(parent_dir))\n",
    "print(parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.search.utils.data_profiling_llm import get_bearer_token\n",
    "\n",
    "client_secret = dbutils.widgets.get(\"client_secret\")\n",
    "\n",
    "bearer_token = get_bearer_token(client_secret)\n",
    "print(bearer_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from src.search.utils.data_profiling_llm import get_openai_embedding\n",
    "\n",
    "embed_start_time = time.time()\n",
    "\n",
    "pdf[\"embedding\"] = pdf.combined.apply(lambda x: get_openai_embedding(client_secret, x))\n",
    "\n",
    "embed_time = time.time() - embed_start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Embedding took {embed_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "yesterday = F.date_sub(F.current_date(), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.databricks.delta.schema.autoMerge.enabled\",\"true\")\n",
    "spark.sql(f\"DROP TABLE IF EXISTS {ml_catalog}.{ml_search_db}.ml_qna_embed\")\n",
    "\n",
    "\n",
    "# Add year, month, and day columns to the DataFrame\n",
    "spark_df = spark.createDataFrame(pdf).withColumn(\"year\", F.year(F.lit(yesterday))) \\\n",
    "                   .withColumn(\"month\", F.year(F.lit(yesterday))) \\\n",
    "                   .withColumn(\"day\", F.year(F.lit(yesterday)))\n",
    "\n",
    "(spark_df\n",
    ".write\n",
    ".format(\"delta\")\n",
    ".mode(\"overwrite\")\n",
    ".option(\"mergeSchema\", \"true\")\n",
    ".partitionBy(\"year\", \"month\", \"day\")\n",
    ".saveAsTable(f\"{ml_catalog}.{ml_search_db}.ml_qna_embed\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qna = spark.sql(\"select * from onedata_us_east_1_shared_dit.nas_raw_lyric_search_dit.ml_qna_embed\")\n",
    "display(df_qna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = df_qna.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf.rename(columns={'id': 'qna_id'}, inplace=True)\n",
    "pdf_exploded = pdf.explode('clientId_ss')\n",
    "pdf_exploded = pdf_exploded[['qna_id', 'clientId_ss','description_t', 'metadata_s', 'embedding']]\n",
    "pdf_exploded = pdf_exploded.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "pdf_exploded['embedding'] = pdf_exploded['embedding'].apply(lambda x: np.array(x).astype(np.float32).tobytes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rvl version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import redis\n",
    "\n",
    "# Redis connection params\n",
    "REDIS_HOST = 'search01d.us.caas.oneadp.com'\n",
    "REDIS_PORT = 443\n",
    "REDIS_PASSWORD = dbutils.widgets.get(\"redis_secret\")\n",
    "\n",
    "# Create Redis client\n",
    "redis_client = redis.Redis(\n",
    "  host=REDIS_HOST,\n",
    "  port=REDIS_PORT,\n",
    "  password=REDIS_PASSWORD,\n",
    "  decode_responses=True, \n",
    "  ssl_cert_reqs=\"none\", \n",
    "  ssl=True)\n",
    "# Test connection\n",
    "redis_client.ping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from redisvl.schema import IndexSchema\n",
    "from redisvl.index import SearchIndex\n",
    "\n",
    "index_name = \"question_answer_json_v0\"\n",
    "\n",
    "schema = IndexSchema.from_dict({\n",
    "  \"index\": {\n",
    "    \"name\": index_name,\n",
    "    \"prefix\": index_name,\n",
    "    \"storage_type\": \"hash\"\n",
    "  },\n",
    "  \"fields\": [\n",
    "    {\"type\" : \"tag\", \"name\" : \"qna_id\"},\n",
    "    {\"type\" : \"tag\", \"name\" : \"clientId_ss\"},\n",
    "    {\"type\" : \"tag\", \"name\" : \"description_t\"},\n",
    "    {\"type\" : \"text\", \"name\" : \"metadata_s\"},\n",
    "    {\n",
    "        \"type\" : \"vector\",\n",
    "        \"name\" : \"embedding\",\n",
    "        \"attrs\" : {\n",
    "            \"dims\": 3072,\n",
    "            \"distance_metric\": \"cosine\",\n",
    "            \"algorithm\": \"flat\",\n",
    "            \"datatype\": \"float32\"\n",
    "        }\n",
    "    }\n",
    "  ],\n",
    "})\n",
    "\n",
    "index = SearchIndex(schema, redis_client)\n",
    "index.create(overwrite=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index.load(pdf_exploded.to_dict(orient=\"records\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index.info()['num_docs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from redisvl.query import VectorQuery\n",
    "from redisvl.query.filter import Tag\n",
    "\n",
    "user_query = \"401k\"\n",
    "vector = get_openai_embedding(client_secret, user_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Tag(\"clientId_ss\") == \"3f346c64-d57b-4b0e-adaa-75be4a3165ca\"\n",
    "\n",
    "v = VectorQuery(\n",
    "    vector=np.array(vector).astype(np.float32).tobytes(),\n",
    "    vector_field_name=\"embedding\",\n",
    "    return_fields=['qna_id', 'description_t', 'metadata_s', 'type_t', 'clientId_ss'],\n",
    "    filter_expression=t\n",
    ")\n",
    "\n",
    "results = index.query(v)\n",
    "display(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
