{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "secret_scope = dbutils.widgets.get(\"secret_scope\")\n",
    "\n",
    "if secret_scope.split(\"-\")[0] == \"prod\":\n",
    "    dbutils.notebook.exit(\"Skip run in prod environment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_catalog = dbutils.widgets.get(\"ml_catalog\")\n",
    "ml_search_db = dbutils.widgets.get(\"ml_search_db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Question and Answer Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "boto3_session = boto3.Session(\n",
    "    botocore_session=dbutils.credentials.getServiceCredentialsProvider(\n",
    "        'service-cred-nas-lifion_ml-sdq-dit'\n",
    "    )\n",
    ")\n",
    "\n",
    "bucket_name = \"ml-models-bucket-appbuild-02\"\n",
    "file_path = \"evaluation_framework/data.pdf\"\n",
    "\n",
    "s3_client = boto3_session.client('s3') \n",
    "local_path = \"file.pdf\"\n",
    "s3_client.download_file(bucket_name, file_path, local_path)\n",
    "\n",
    "loader = PyPDFLoader(local_path)\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# set up the file loader/extractor and text splitter to create chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=2500, chunk_overlap=0\n",
    ")\n",
    "chunks = loader.load_and_split(text_splitter)\n",
    "\n",
    "print(\"Done preprocessing. Created\", len(chunks), \"chunks of the original pdf\", len(documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    [chunk.page_content for i, chunk in enumerate(chunks)],\n",
    "    columns=[\"reference\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "current_dir = Path.cwd()\n",
    "parent_dir = current_dir.parent.parent.parent\n",
    "sys.path.append(str(parent_dir))\n",
    "print(parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.search.utils.data_profiling_llm import get_bearer_token\n",
    "\n",
    "client_secret = dbutils.widgets.get(\"client_secret\")\n",
    "\n",
    "bearer_token = get_bearer_token(client_secret)\n",
    "print(bearer_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from src.search.utils.data_profiling_llm import get_openai_embedding\n",
    "\n",
    "embed_start_time = time.time()\n",
    "\n",
    "df[\"embedding\"] = df.reference.apply(lambda x: get_openai_embedding(client_secret, str(x)))\n",
    "\n",
    "embed_time = time.time() - embed_start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Embedding took {embed_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "yesterday = F.date_sub(F.current_date(), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.databricks.delta.schema.autoMerge.enabled\",\"true\")\n",
    "spark.sql(f\"DROP TABLE IF EXISTS {ml_catalog}.{ml_search_db}.ml_qna_kc_embed\")\n",
    "\n",
    "\n",
    "# Add year, month, and day columns to the DataFrame\n",
    "spark_df = spark.createDataFrame(df).withColumn(\"year\", F.year(F.lit(yesterday))) \\\n",
    "                   .withColumn(\"month\", F.year(F.lit(yesterday))) \\\n",
    "                   .withColumn(\"day\", F.year(F.lit(yesterday)))\n",
    "\n",
    "(spark_df\n",
    ".write\n",
    ".format(\"delta\")\n",
    ".mode(\"overwrite\")\n",
    ".option(\"mergeSchema\", \"true\")\n",
    ".partitionBy(\"year\", \"month\", \"day\")\n",
    ".saveAsTable(f\"{ml_catalog}.{ml_search_db}.ml_qna_kc_embed\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qna = spark.sql(\"select * from onedata_us_east_1_shared_dit.nas_raw_lyric_search_dit.ml_qna_kc_embed\")\n",
    "display(df_qna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = df_qna.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "pdf['embedding'] = pdf['embedding'].apply(lambda x: np.array(x).astype(np.float32).tobytes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rvl version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import redis\n",
    "\n",
    "# Redis connection params\n",
    "REDIS_HOST = 'search01d.us.caas.oneadp.com'\n",
    "REDIS_PORT = 443\n",
    "REDIS_PASSWORD = dbutils.widgets.get(\"redis_secret\")\n",
    "\n",
    "# Create Redis client\n",
    "redis_client = redis.Redis(\n",
    "  host=REDIS_HOST,\n",
    "  port=REDIS_PORT,\n",
    "  password=REDIS_PASSWORD,\n",
    "  decode_responses=True, \n",
    "  ssl_cert_reqs=\"none\", \n",
    "  ssl=True)\n",
    "# Test connection\n",
    "redis_client.ping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from redisvl.schema import IndexSchema\n",
    "from redisvl.index import SearchIndex\n",
    "\n",
    "index_name = \"question_answer_pdf_v0\"\n",
    "\n",
    "schema = IndexSchema.from_dict({\n",
    "  \"index\": {\n",
    "    \"name\": index_name,\n",
    "    \"prefix\": index_name,\n",
    "    \"storage_type\": \"hash\"\n",
    "  },\n",
    "  \"fields\": [\n",
    "    {\"type\" : \"text\", \"name\" : \"reference\"},\n",
    "    {\n",
    "        \"type\" : \"vector\",\n",
    "        \"name\" : \"embedding\",\n",
    "        \"attrs\" : {\n",
    "            \"dims\": 3072,\n",
    "            \"distance_metric\": \"cosine\",\n",
    "            \"algorithm\": \"flat\",\n",
    "            \"datatype\": \"float32\"\n",
    "        }\n",
    "    }\n",
    "  ],\n",
    "})\n",
    "\n",
    "index = SearchIndex(schema, redis_client)\n",
    "index.create(overwrite=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index.load(pdf.to_dict(orient=\"records\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index.info()['num_docs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from redisvl.query import VectorQuery\n",
    "\n",
    "user_query = \"How do I report a workplace safety concern? | If you observe or become aware of any unsafe condition, you must promptly notify your supervisor and the Human Resources Department so that the Company can take action to correct it.\"\n",
    "vector = get_openai_embedding(client_secret, user_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = VectorQuery(\n",
    "    vector=np.array(vector).astype(np.float32).tobytes(),\n",
    "    vector_field_name=\"embedding\",\n",
    "    num_results=3,\n",
    "    return_fields=['reference'],\n",
    "    return_score=True\n",
    ")\n",
    "\n",
    "results = index.query(v)\n",
    "display(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
