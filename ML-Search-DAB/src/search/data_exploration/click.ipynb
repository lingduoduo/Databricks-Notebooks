{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_catalog = dbutils.widgets.get(\"ml_catalog\")\n",
    "ml_search_db = dbutils.widgets.get(\"ml_search_db\")\n",
    "\n",
    "df_click = spark.sql(f\"\"\"select * from {ml_catalog}.{ml_search_db}.ml_search_with_click\n",
    "                     where action = 'actions' or action = 'people' \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Score Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = df_click.orderBy(F.rand()).limit(10000).toPandas()\n",
    "pdf['resPos'] = pdf['resPos'].astype(int)\n",
    "pdf[['resPos', 'finalScore']].groupby('resPos').describe().applymap(lambda x: '%.2f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf[['resPos', 'click']].groupby('resPos').describe().applymap(lambda x: '%.2f' % x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of Irrelavant Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "current_dir = Path.cwd()\n",
    "parent_dir = current_dir.parent.parent\n",
    "sys.path.append(str(parent_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from search.utils.data_exploration import drop_docs_analysis, compare_docs_with_clicks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_click = drop_docs_analysis(df_click)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(df_click)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_click.select('queryId').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aggregated = df_click.groupBy('resPos').agg(\n",
    "    F.count('keep_label').alias('startDocs'),\n",
    "    F.sum(F.col('keep_label')).alias('keepDocs'),\n",
    "    F.sum(F.col('click')).alias('startClicks'),\n",
    "    F.sum(F.col('keep_label') * F.col('click')).alias('keepClicks')\n",
    ").orderBy('resPos')\n",
    "\n",
    "df_aggregated = (df_aggregated\n",
    ".withColumn(\n",
    "    'KeepDoc %', F.round(((F.col('keepDocs') / F.col('startDocs')) * 100), 2))\n",
    ".withColumn(\n",
    "    'KeepClicks %', \n",
    "    F.when(F.col('startClicks') == 0, 100).otherwise(F.round((F.col('keepClicks') / F.col('startClicks')) * 100, 2)))\n",
    ".withColumn(\n",
    "    'Start CTR %',\n",
    "    F.round(F.col('startClicks') / F.col('startDocs')*100, 2))\n",
    ".withColumn(\n",
    "    'After CTR %',\n",
    "    F.round(F.col('keepClicks') / F.col('keepDocs')*100, 2))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_aggregated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_docs_with_clicks(df_aggregated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extreme Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dropped_clicks = (df_click\n",
    "    .filter((F.col(\"click\") == 1) & (F.col(\"keep_label\") == 0))\n",
    "    .withColumn(\"query\", F.col(\"label\"))  \n",
    "    .withColumn(\"client_id\", F.col(\"_token_client_id\"))  \n",
    "    .groupBy(\n",
    "        F.col(\"resPos\"),\n",
    "        F.col(\"action\"),\n",
    "        F.col(\"query\"),\n",
    "        F.col(\"click_label\"),\n",
    "        F.col(\"client_id\")\n",
    "    )\n",
    "    .agg(F.count(\"*\").alias(\"count\"))\n",
    "    .orderBy(F.col(\"count\").desc())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_dropped_clicks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collect_traceIds = (df_click\n",
    "    .filter((F.col(\"click\") == 1) & (F.col(\"keep_label\") == 0))\n",
    "    .select(F.col(\"action\"),\n",
    "            F.col(\"client_id\"),\n",
    "            F.col(\"traceId\"), \n",
    "            F.col(\"resPos\"),\n",
    "            F.col(\"label\"), \n",
    "            F.col(\"click_label\"),\n",
    "            F.col(\"finalScore\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traceIds = (collect_traceIds\n",
    "    .orderBy(F.col(\"finalScore\").desc())\n",
    "    .select(F.col(\"traceId\"))\n",
    "    .collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(traceIds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_ids_df = spark.createDataFrame(traceIds, [\"traceId\"])\n",
    "display(trace_ids_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_ids = [row[\"traceId\"] for row in traceIds]\n",
    "# limit the number of trace_ids to 1024 to avoid exceeding the number of choices for the dropdown widget.\n",
    "if len(trace_ids) > 1000:\n",
    "    trace_ids = trace_ids[:1000]\n",
    "default_trace_id = trace_ids[0] if len(trace_ids) > 0 else \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbutils.widgets.dropdown(\n",
    "    \"trace_id\",\n",
    "    default_trace_id,\n",
    "    trace_ids\n",
    ")\n",
    "trace_id = dbutils.widgets.get(\"trace_id\")\n",
    "print(f\"trace_id: {trace_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(spark.sql(f\"\"\"select \n",
    "                  traceId, \n",
    "                  resPos,\n",
    "                  client_id,\n",
    "                  label,\n",
    "                  click_label,\n",
    "                  click_category,\n",
    "                  click_details_caption\n",
    "                  from {ml_catalog}.{ml_search_db}.ml_search_with_click\n",
    "                     where traceId = '{trace_id}'\n",
    "                     order by resPos\n",
    "                     \"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(spark.sql(f\"\"\"select \n",
    "                  traceId, \n",
    "                  resPos,\n",
    "                  client_id,\n",
    "                  _id,\n",
    "                  caption,\n",
    "                  subtitle,\n",
    "                  solrScore,\n",
    "                  finalScore\n",
    "                  from {ml_catalog}.{ml_search_db}.ml_search_action\n",
    "                     where traceId = '{trace_id}'\n",
    "                     order by resPos\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(spark.sql(f\"\"\"select \n",
    "                  traceId, \n",
    "                  resPos,\n",
    "                  client_id,\n",
    "                  _id,\n",
    "                  legalName, \n",
    "                  displayName, \n",
    "                  eID, \n",
    "                  location, \n",
    "                  position,\n",
    "                  finalScore\n",
    "                  from {ml_catalog}.{ml_search_db}.ml_search_people\n",
    "                     where traceId = '{trace_id}'\n",
    "                     order by resPos\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of Irrelavant Results for Individual Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_ids = [row[\"_token_client_id\"] for row in spark.sql(f\"\"\"select distinct _token_client_id from {ml_catalog}.{ml_search_db}.ml_search_with_click\n",
    "                                                           where action = 'actions' or action = 'people' \"\"\").collect()]\n",
    "\n",
    "dbutils.widgets.dropdown(\n",
    "    \"client_id\",\n",
    "    \"002\",\n",
    "    client_ids\n",
    ")\n",
    "client_id = dbutils.widgets.get(\"client_id\")\n",
    "print(f\"client_id: {client_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aggregated_client = df_click.filter(F.col('_token_client_id') == client_id).groupBy('resPos').agg(\n",
    "    F.count('keep_label').alias('startDocs'),\n",
    "    F.sum(F.col('keep_label')).alias('keepDocs'),\n",
    "    F.sum(F.col('click')).alias('startClicks'),\n",
    "    F.sum(F.col('keep_label') * F.col('click')).alias('keepClicks')\n",
    ").orderBy('resPos')\n",
    "\n",
    "df_aggregated_client = (df_aggregated_client\n",
    ".withColumn(\n",
    "    'KeepDoc %', F.round(((F.col('keepDocs') / F.col('startDocs')) * 100), 2))\n",
    ".withColumn(\n",
    "    'KeepClicks %', \n",
    "    F.when(F.col('startClicks') == 0, 100).otherwise(F.round((F.col('keepClicks') / F.col('startClicks')) * 100, 2)))\n",
    ".withColumn(\n",
    "    'Start CTR %',\n",
    "    F.round(F.col('startClicks') / F.col('startDocs')*100, 2))\n",
    ".withColumn(\n",
    "    'After CTR %',\n",
    "    F.round(F.col('keepClicks') / F.col('keepDocs')*100, 2))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_docs_with_clicks(df_aggregated_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extreme Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dropped_clicks = (df_click.filter(F.col('_token_client_id') == client_id)\n",
    "    .filter((F.col(\"click\") == 1) & (F.col(\"keep_label\") == 0))\n",
    "    .withColumn(\"query\", F.col(\"label\"))  \n",
    "    .withColumn(\"client_id\", F.col(\"_token_client_id\"))  \n",
    "    .groupBy(\n",
    "        F.col(\"resPos\"),\n",
    "        F.col(\"action\"),\n",
    "        F.col(\"query\"),\n",
    "        F.col(\"click_label\"),\n",
    "        F.col(\"client_id\")\n",
    "    )\n",
    "    .agg(F.count(\"*\").alias(\"count\"))\n",
    "    .orderBy(F.col(\"count\").desc())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_dropped_clicks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
