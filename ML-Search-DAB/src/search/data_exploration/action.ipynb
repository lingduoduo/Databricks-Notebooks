{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_catalog = dbutils.widgets.get(\"ml_catalog\")\n",
    "ml_search_db = dbutils.widgets.get(\"ml_search_db\")\n",
    "df_action = spark.sql(f\"select * from {ml_catalog}.{ml_search_db}.ml_search_action\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Score Distribution for Search Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = df_action.orderBy(F.rand()).limit(10000).toPandas()\n",
    "pdf['resPos'] = pdf['resPos'].astype(int)\n",
    "pdf[['resPos', 'finalScore']].groupby('resPos').describe().applymap(lambda x: '%.2f' % x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of Irrelavant Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "current_dir = Path.cwd()\n",
    "parent_dir = current_dir.parent.parent\n",
    "sys.path.append(str(parent_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from search.utils.data_exploration import drop_docs_analysis, compare_docs_with_clicks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_action = drop_docs_analysis(df_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(df_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_action.select('queryId').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aggregated = df_action.groupBy('resPos').agg(\n",
    "    F.count('keep_label').alias('startDocs'),\n",
    "    F.sum(F.col('keep_label')).alias('keepDocs')\n",
    ").orderBy('resPos')\n",
    "\n",
    "df_aggregated = df_aggregated.withColumn(\n",
    "    'keepDocs %', (F.col('keepDocs') / F.col('startDocs')) * 100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_aggregated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the total sums\n",
    "total_sums = df_aggregated.agg(\n",
    "    F.sum('startDocs').alias('totalstartDocs'),\n",
    "    F.sum('keepDocs').alias('totalkeepDocs')\n",
    ").collect()[0]\n",
    "\n",
    "# Calculate the percentage\n",
    "total_start_doc_count = total_sums['totalstartDocs']\n",
    "total_final_doc_count = total_sums['totalkeepDocs']\n",
    "percentage = (total_final_doc_count / total_start_doc_count) * 100\n",
    "\n",
    "if total_start_doc_count > 0:\n",
    "    percentage = (1 - (total_final_doc_count / total_start_doc_count)) * 100\n",
    "    print(f\"Total Dropped Doc%: {percentage:.2f}%\")\n",
    "else:\n",
    "    print(\"No documents were dropped.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of Irrelavant Search Results for Individual Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_ids = [row[\"_token_client_id\"] for row in spark.sql(f\"select distinct _token_client_id from {ml_catalog}.{ml_search_db}.ml_search_action\").collect()]\n",
    "\n",
    "print(f\"number of clients: {len(client_ids)}\")\n",
    "\n",
    "dbutils.widgets.dropdown(\n",
    "    \"client_id\",\n",
    "    \"002\",\n",
    "    client_ids\n",
    ")\n",
    "client_id = dbutils.widgets.get(\"client_id\")\n",
    "print(f\"Analysis of client_id: {client_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aggregated_client = df_action.filter(F.col('_token_client_id') == client_id).groupBy('resPos').agg(\n",
    "    F.count('keep_label').alias('startDocs'),\n",
    "    F.sum(F.col('keep_label')).alias('keepDocs'),\n",
    ").orderBy('resPos')\n",
    "\n",
    "df_aggregated_client = df_aggregated_client.withColumn(\n",
    "    'keepDocs %', F.round((F.col('keepDocs') / F.col('startDocs')) * 100, 2)\n",
    ")\n",
    "display(df_aggregated_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the total sums\n",
    "total_sums = df_aggregated_client.agg(\n",
    "    F.sum('startDocs').alias('totalstartDocs'),\n",
    "    F.sum('keepDocs').alias('totalkeepDocs')\n",
    ").collect()[0]\n",
    "\n",
    "# Calculate the percentage\n",
    "total_start_doc_count = total_sums['totalstartDocs']\n",
    "total_final_doc_count = total_sums['totalkeepDocs']\n",
    "\n",
    "if total_start_doc_count > 0:\n",
    "    percentage = (1 - (total_final_doc_count / total_start_doc_count)) * 100\n",
    "    print(f\"Total Dropped Doc%: {percentage:.2f}%\")\n",
    "else:\n",
    "    print(\"No documents were dropped.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Score Distribution for Click Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_click = spark.sql(f\"\"\"select * from {ml_catalog}.{ml_search_db}.ml_search_with_click\n",
    "                     where action = 'actions' \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_click = drop_docs_analysis(df_click)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(df_click)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_click.select('queryId').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aggregated = df_click.groupBy('resPos').agg(\n",
    "    F.count('keep_label').alias('startDocs'),\n",
    "    F.sum(F.col('keep_label')).alias('keepDocs'),\n",
    "    F.sum(F.col('click')).alias('startClicks'),\n",
    "    F.sum(F.col('keep_label') * F.col('click')).alias('keepClicks')\n",
    ").orderBy('resPos')\n",
    "\n",
    "df_aggregated = (df_aggregated\n",
    ".withColumn(\n",
    "    'KeepDoc %', F.round(((F.col('keepDocs') / F.col('startDocs')) * 100), 2))\n",
    ".withColumn(\n",
    "    'KeepClicks %', \n",
    "    F.when(F.col('startClicks') == 0, 100).otherwise(F.round((F.col('keepClicks') / F.col('startClicks')) * 100, 2)))\n",
    ".withColumn(\n",
    "    'Start CTR %',\n",
    "    F.round(F.col('startClicks') / F.col('startDocs')*100, 2))\n",
    ".withColumn(\n",
    "    'After CTR %',\n",
    "    F.round(F.col('keepClicks') / F.col('keepDocs')*100, 2))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_aggregated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_docs_with_clicks(df_aggregated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of Irrelavant Results for Individual Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_ids = [row[\"_token_client_id\"] for row in spark.sql(f\"\"\"select distinct _token_client_id from {ml_catalog}.{ml_search_db}.ml_search_with_click where action = 'actions' \"\"\").collect()]\n",
    "\n",
    "dbutils.widgets.dropdown(\n",
    "    \"client_id\",\n",
    "    \"002\",\n",
    "    client_ids\n",
    ")\n",
    "client_id = dbutils.widgets.get(\"client_id\")\n",
    "print(f\"client_id: {client_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aggregated_client = df_click.filter(F.col('_token_client_id') == client_id).groupBy('resPos').agg(\n",
    "    F.count('keep_label').alias('startDocs'),\n",
    "    F.sum(F.col('keep_label')).alias('keepDocs'),\n",
    "    F.sum(F.col('click')).alias('startClicks'),\n",
    "    F.sum(F.col('keep_label') * F.col('click')).alias('keepClicks')\n",
    ").orderBy('resPos')\n",
    "\n",
    "df_aggregated_client = (df_aggregated_client\n",
    ".withColumn(\n",
    "    'KeepDoc %', F.round(((F.col('keepDocs') / F.col('startDocs')) * 100), 2))\n",
    ".withColumn(\n",
    "    'KeepClicks %', \n",
    "    F.when(F.col('startClicks') == 0, 100).otherwise(F.round((F.col('keepClicks') / F.col('startClicks')) * 100, 2)))\n",
    ".withColumn(\n",
    "    'Start CTR %',\n",
    "    F.round(F.col('startClicks') / F.col('startDocs')*100, 2))\n",
    ".withColumn(\n",
    "    'After CTR %',\n",
    "    F.round(F.col('keepClicks') / F.col('keepDocs')*100, 2))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_docs_with_clicks(df_aggregated_client)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
