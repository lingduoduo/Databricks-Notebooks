{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_catalog = dbutils.widgets.get(\"ml_catalog\")\n",
    "ml_search_db = dbutils.widgets.get(\"ml_search_db\")\n",
    "\n",
    "df_action = spark.sql(f\"\"\"\n",
    "with click as (\n",
    "    select request_correlation_id,\n",
    "        _token_session_id, \n",
    "        _token_associate_id, \n",
    "        object_id, \n",
    "        time_stamp, \n",
    "        label, \n",
    "        client_id, \n",
    "        category, \n",
    "        details_caption \n",
    "    from {ml_catalog}.{ml_search_db}.ml_search_click \n",
    "    where request_correlation_id is not null and lower(request_correlation_id) != 'nan'\n",
    "),\n",
    "\n",
    "search_click as (\n",
    "        select search.request_correlation_id,\n",
    "        search._token_client_id as client_id,\n",
    "        search.label AS query,\n",
    "        search.resPos,\n",
    "        search.traceId,\n",
    "        search.caption,\n",
    "        search.subtitle,\n",
    "        search.solrScore,\n",
    "        search.finalScore,\n",
    "        rank() over (partition by search.request_correlation_id, search.resPos, search.traceId order by click.time_stamp) as rank,\n",
    "        1 AS click_count,\n",
    "        click._token_session_id as click_session_id, \n",
    "        click._token_associate_id as click_associate_id, \n",
    "        click.object_id as click_object_id, \n",
    "        click.time_stamp as click_time_stamp, \n",
    "        click.label as click_label, \n",
    "        click.client_id as click_client_id, \n",
    "        click.category as click_category, \n",
    "        click.details_caption as click_details_caption\n",
    "    from {ml_catalog}.{ml_search_db}.ml_search_action search\n",
    "    inner join click\n",
    "    on search.request_correlation_id = click.request_correlation_id\n",
    "    and search._id = click.object_id\n",
    "),\n",
    "\n",
    "click_aggregation AS (\n",
    "    SELECT query,\n",
    "           caption,\n",
    "           subtitle,\n",
    "           sum(click_count) AS total_clicks,\n",
    "           DENSE_RANK() OVER (PARTITION BY query ORDER BY sum(click_count) DESC) AS action_rank\n",
    "    FROM search_click\n",
    "    WHERE rank = 1\n",
    "    GROUP BY query, caption, subtitle\n",
    ")\n",
    "\n",
    "SELECT query,\n",
    "        caption,\n",
    "        subtitle,\n",
    "        total_clicks,\n",
    "        action_rank,\n",
    "        max(action_rank) over (PARTITION BY query) AS max_action_rank\n",
    "FROM click_aggregation\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "filtered_df = (df_action.filter((col(\"max_action_rank\") >= 3) & (col(\"action_rank\") <= 3)) \n",
    "    .select(\"query\", \"caption\", \"subtitle\", \"total_clicks\", \"action_rank\", \"max_action_rank\") \n",
    "    .orderBy([\"query\", \"action_rank\"]))\n",
    "\n",
    "display(filtered_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_action = df_action.toPandas()\n",
    "pdf_action['combined'] = pdf_action.apply(\n",
    "    lambda x: x.caption if x.caption.lower() == x.subtitle.lower() else ','.join([x.caption, x.subtitle]), \n",
    "    axis=1\n",
    ")\n",
    "documents = \"\\n\\n\".join(pdf_action.combined)\n",
    "documents[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "current_dir = Path.cwd()\n",
    "parent_dir = current_dir.parent.parent\n",
    "sys.path.append(str(parent_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from search.utils.data_profiling_nlp import CustomTextSplitter\n",
    "\n",
    "splitter = CustomTextSplitter(separator=\"\\n\\n\")\n",
    "processed_tokens = splitter.split_text(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import pandas as pd\n",
    "\n",
    "words = ','.join(processed_tokens)\n",
    "w = words.split(',')\n",
    "\n",
    "most_common_keywords = Counter(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(most_common_keywords.most_common(100), columns=['keyword', 'count'])\n",
    "df = df.sort_values(by='count', ascending=False)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "secret_scope = dbutils.widgets.get(\"secret_scope\")\n",
    "\n",
    "if secret_scope.split(\"-\")[0] == \"prod\":\n",
    "    dbutils.notebook.exit(\"Skip run in prod environment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Redis Auto Suggest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import redis\n",
    "\n",
    "# Redis connection params\n",
    "REDIS_HOST = 'search01d.us.caas.oneadp.com'\n",
    "REDIS_PORT = 443\n",
    "REDIS_PASSWORD = dbutils.widgets.get(\"redis_secret\")\n",
    "\n",
    "# Create Redis client\n",
    "redis_client = redis.Redis(\n",
    "  host=REDIS_HOST,\n",
    "  port=REDIS_PORT,\n",
    "  password=REDIS_PASSWORD,\n",
    "  decode_responses=True, \n",
    "  ssl_cert_reqs=\"none\", \n",
    "  ssl=True)\n",
    "# Test connection\n",
    "redis_client.ping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "redis_client.dbsize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# redis_client.flushall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from redis.commands.search.suggestion import Suggestion\n",
    "\n",
    "total = 0\n",
    "BATCH_SIZE = 10_000\n",
    "\n",
    "with redis_client.pipeline(transaction=False) as pipe:\n",
    "    batch_count = 0\n",
    "    for key, val in most_common_keywords.items():\n",
    "        pipe.ft().sugadd(\n",
    "            'top_action_keywords',\n",
    "            Suggestion(key, float(val)),\n",
    "            increment=True,\n",
    "        )\n",
    "        total += 1\n",
    "        batch_count += 1\n",
    "\n",
    "        if batch_count >= BATCH_SIZE:\n",
    "            pipe.execute()\n",
    "            batch_count = 0\n",
    "\n",
    "    if batch_count > 0:\n",
    "        pipe.execute()\n",
    "\n",
    "print(f\"Inserted/updated {total:,} keywords into 'top_action_keywords'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "\n",
    "def get_suggestions(redis_client, prefix: str, max_results: int = 10, fuzzy: bool = True) -> List[Tuple[str, float]]:\n",
    "    suggestions = redis_client.ft().sugget(\n",
    "        'top_action_keywords',\n",
    "        prefix,\n",
    "        num=max_results,\n",
    "        fuzzy=fuzzy,\n",
    "        with_scores=True\n",
    "    )\n",
    "    \n",
    "    if not suggestions:\n",
    "        return []\n",
    "\n",
    "    return [(s.string, s.score) for s in suggestions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_suggestions(redis_client, \"ma\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
